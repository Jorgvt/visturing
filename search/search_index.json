{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Visturing: A Turing Test for Artificial Nets devoted to Vision","text":"<p>This repository contains the source code, datasets, and experiments associated with the research paper \"A Turing Test for Artificial Nets devoted to Vision\", published in Frontiers in Artificial Intelligence (2025).</p> <p>The project implements a comprehensive evaluation framework (a visual \"Turing Test\") to assess whether Artificial Neural Networks (ANNs) exhibit the same low-level spatio-chromatic properties as the human Retina-V1 pathway.</p>"},{"location":"#overview","title":"Overview","text":"<p>Deep networks have achieved remarkable success in computer vision, but do they actually \"see\" like humans? This work proposes that for an ANN to be considered a valid biological model, it must pass rigorous psychophysical and physiological tests, not just achieve high accuracy on segmentation or classification tasks.</p> <p>Key Contributions:</p> <p>The Test Suite: A collection of 10 qualitative and quantitative tests covering fundamental properties of the visual system (e.g., contrast sensitivity, masking, frequency tuning).</p> <p>Model Comparison: We evaluate three distinct modeling approaches:</p> <p>Parametric Model: Optimized via Maximum Differentiation (MaxDiff).</p> <p>Non-Parametric Model (PerceptNet): Optimized to maximize correlation with human subjective distortion.</p> <p>Segmentation Model: The same architecture as PerceptNet, but trained for a technical segmentation task.</p> <p>Results: The code reproduces the paper's findings, showing that models trained on human perception (PerceptNet) align significantly better with biological behavior than those trained for pure computer vision tasks.</p>"},{"location":"#installation","title":"Installation","text":"<p>To reproduce the experiments, clone this repository and install the required dependencies. It is recommended to use a virtual environment (Anaconda or venv).</p> <pre><code># Install the repository\npip install git+https://github.com/Jorgvt/visturing.git\n</code></pre>"},{"location":"#usage-reproduction","title":"Usage &amp; Reproduction","text":"<p>The primary results and figures from the paper are generated using Jupyter Notebooks.</p> <p>To evaluate some models check the folder use_examples</p> <p>Repository Structure</p> <p>use_examples/: Examples to evaluate classical models using the library. It aomatically downloads the data in /Data if necessary.</p> <p>visturing/: Scripts implementing the 10 psychophysical/physiological tests.</p>"},{"location":"#citation","title":"Citation","text":"<p>If you use this code, data, or methodology in your research, please cite the original article:</p> <pre><code>@article{vila2025turing,\n  title={A Turing Test for Artificial Nets devoted to Vision},\n  author={Vila-Tom\u00e1s, Jorge and Hern\u00e1ndez-C\u00e1mara, Pablo and Li, Qiang and Laparra, Valero and Malo, Jes\u00fas},\n  journal={Frontiers in Artificial Intelligence},\n  year={2025},\n  doi={10.3389/frai.2025.1665874},\n  url={https://www.frontiersin.org/journals/artificial-intelligence/articles/10.3389/frai.2025.1665874/abstract}\n}\n</code></pre> <p>\ud83d\udc65 Authors</p> <p>Jorge Vila-Tom\u00e1s (Universitat de Val\u00e8ncia)</p> <p>Pablo Hern\u00e1ndez-C\u00e1mara (Universitat de Val\u00e8ncia)</p> <p>Qiang Li (Georgia Institute of Technology)</p> <p>Valero Laparra (Universitat de Val\u00e8ncia)</p> <p>Jes\u00fas Malo (Universitat de Val\u00e8ncia) - Corresponding Author</p> <p>For any questions regarding the code or the paper, please open an Issue in this repository.</p> <p>Image Processing Lab (IPL), Universitat de Val\u00e8ncia.</p>"},{"location":"api/","title":"API Reference","text":""},{"location":"api/#visturing","title":"<code>visturing</code>","text":""},{"location":"api/#visturing.properties","title":"<code>properties</code>","text":""},{"location":"api/#visturing.properties.jax","title":"<code>jax</code>","text":""},{"location":"api/#visturing.properties.jax.math_utils","title":"<code>math_utils</code>","text":""},{"location":"api/#visturing.properties.jax.math_utils.kendall_correlation","title":"<code>kendall_correlation(x, y)</code>","text":"Source code in <code>visturing/properties/jax/math_utils.py</code> <pre><code>def kendall_correlation(x, y):\n    n = x.shape[0]\n\n    # 1. Broadcast to compare every element with every other element\n    # shape: (N, 1) - (1, N) -&gt; (N, N)\n    diff_x = x[:, None] - x[None, :]\n    diff_y = y[:, None] - y[None, :]\n\n    # 2. Compute signs\n    # sgn(x_i - x_j)\n    sign_x = jnp.sign(diff_x)\n    sign_y = jnp.sign(diff_y)\n\n    # 3. Compute Concordance\n    # Result is 1 if concordant, -1 if discordant, 0 if tied\n    concordance = sign_x * sign_y\n\n    # 4. Sum and Normalize\n    # We sum the whole matrix (excluding diagonal where result is 0).\n    # Since the matrix is symmetric, we divide by n(n-1) rather than n(n-1)/2\n    # to account for the double counting.\n    tau = jnp.sum(concordance) / (n * (n - 1))\n\n    return tau\n</code></pre>"},{"location":"api/#visturing.properties.jax.math_utils.pearson_correlation","title":"<code>pearson_correlation(vec1, vec2)</code>","text":"Source code in <code>visturing/properties/jax/math_utils.py</code> <pre><code>def pearson_correlation(vec1, vec2):\n    vec1 = vec1.squeeze()\n    vec2 = vec2.squeeze()\n    vec1_mean = vec1.mean()\n    vec2_mean = vec2.mean()\n    num = vec1 - vec1_mean\n    num *= vec2 - vec2_mean\n    num = num.sum()\n    denom = ((vec1-vec1_mean)**2).sum()**(1/2)\n    denom *= ((vec2 - vec2_mean) ** 2).sum()**(1/2)\n    return num / denom\n</code></pre>"},{"location":"api/#visturing.properties.jax.prop1","title":"<code>prop1</code>","text":""},{"location":"api/#visturing.properties.jax.prop1.download_data","title":"<code>download_data(data_path)</code>","text":"Source code in <code>visturing/properties/jax/prop1.py</code> <pre><code>def download_data(data_path, # Path to download the data\n                  ):\n    # if not os.path.exists(data_path):\n    #     os.makedirs(data_path)\n    data_url = \"https://zenodo.org/records/17700252/files/Experiment_1.zip\"\n    path = wget.download(data_url)\n    with ZipFile(path) as zipObj:\n        zipObj.extractall(data_path)\n    os.remove(path)\n    return os.path.join(data_path, \"Experiment_1\")\n</code></pre>"},{"location":"api/#visturing.properties.jax.prop1.evaluate","title":"<code>evaluate(calculate_diffs, data_path='Data/Experiment_1', gt_path='ground_truth_decalogo')</code>","text":"Source code in <code>visturing/properties/jax/prop1.py</code> <pre><code>def evaluate(calculate_diffs,\n             data_path: str = \"Data/Experiment_1\",\n             gt_path: str = \"ground_truth_decalogo\",\n             ): # Tuple (lambdas, diffs, correlation)\n\n    if not os.path.exists(data_path):\n        data_path = download_data(\"/\".join(data_path.split(\"/\")[:-1]))\n\n    imgs, ref_img, lambdas = load_data(data_path)\n\n    diffs = calculate_diffs(imgs, ref_img[None,...])\n\n    x, a, _, _ = load_ground_truth(gt_path)\n    a_interp = np.interp(lambdas, x, a)\n    corr = pearson_correlation(diffs, a_interp)\n\n    return {\"lambdas\": lambdas,\n            \"diffs\": diffs,\n            \"correlations\":\n                {\"pearson\": corr},\n            }\n</code></pre>"},{"location":"api/#visturing.properties.jax.prop1.load_data","title":"<code>load_data(root_path)</code>","text":"Source code in <code>visturing/properties/jax/prop1.py</code> <pre><code>def load_data(root_path: str,\n              ): # Tuple (imgs, reference_image)\n    ref_path = os.path.join(root_path, \"im_ref.png\")\n    lambdas = np.load(os.path.join(root_path, \"lambdas.npy\"))\n\n    imgs_path = [p for p in glob(os.path.join(root_path, \"*png\")) if \"ref\" not in p]\n    imgs_path = list(natsorted(imgs_path))\n\n    def load_img(path):\n        img = cv2.imread(path)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        return img\n\n    ref_img = load_img(ref_path)\n    imgs = np.array([load_img(p) for p in imgs_path])\n    lambdas = np.linspace(lambdas.min(), lambdas.max(), num=len(imgs))\n\n    return imgs, ref_img, lambdas\n</code></pre>"},{"location":"api/#visturing.properties.jax.prop1.load_ground_truth","title":"<code>load_ground_truth(root_path='ground_truth_decalogo')</code>","text":"Source code in <code>visturing/properties/jax/prop1.py</code> <pre><code>def load_ground_truth(root_path: str = \"ground_truth_decalogo\", # Path to the root containing all the ground truth files\n                      ): # Tuple (x, achromatic, red-green, yellow-blue)\n    data = sio.loadmat(os.path.join(root_path, \"spectral_sensitivities.mat\"))\n    data = data[\"spectral_sensitivities\"]\n\n    x = data[0]\n    a = data[1]\n    rg = data[2]\n    yb = data[3]\n\n    return (x, a, rg, yb)\n</code></pre>"},{"location":"api/#visturing.properties.jax.prop1.plot_ground_truth","title":"<code>plot_ground_truth(x, a, rg, yb)</code>","text":"Source code in <code>visturing/properties/jax/prop1.py</code> <pre><code>def plot_ground_truth(x,\n                      a,\n                      rg,\n                      yb,\n                      ): #\u00a0Returns both the fig and axes objects\n    fig, axes = plt.subplots(1,2, sharex=True, sharey=False, figsize=(10,4))\n    axes[0].plot(x, a, \"k\", label=\"Achromatic\")\n\n    axes[0].set_xlim([380, 720])\n    axes[0].set_ylim([0, 1.1])\n    axes[0].legend()\n\n    axes[1].plot(x, rg, \"r\", label=\"Red-Green\")\n    axes[1].plot(x, yb, \"b\", label=\"Yellow-Blue\")\n    axes[1].set_xlim([380, 720])\n    axes[1].set_ylim([-0.7, 0.7])\n\n    axes[1].legend()\n\n    axes[0].set_xlabel(r\"Wavelength ($\\lambda$)\")\n    axes[0].set_ylabel(\"Visibility\")\n    axes[1].set_xlabel(r\"Wavelength ($\\lambda$)\")\n\n    return fig, axes\n</code></pre>"},{"location":"api/#visturing.properties.jax.prop10","title":"<code>prop10</code>","text":""},{"location":"api/#visturing.properties.jax.prop10.download_data","title":"<code>download_data(data_path)</code>","text":"Source code in <code>visturing/properties/jax/prop10.py</code> <pre><code>def download_data(data_path, # Path to download the data\n                  ):\n    # if not os.path.exists(data_path):\n    #     os.makedirs(data_path)\n    data_url = \"https://zenodo.org/records/17700252/files/Experiment_10.zip\"\n    path = wget.download(data_url)\n    with ZipFile(path) as zipObj:\n        zipObj.extractall(data_path)\n    os.remove(path)\n    return os.path.join(data_path, \"Experiment_10\")\n</code></pre>"},{"location":"api/#visturing.properties.jax.prop10.evaluate","title":"<code>evaluate(calculate_diffs, data_path, gt_path)</code>","text":"Source code in <code>visturing/properties/jax/prop10.py</code> <pre><code>def evaluate(calculate_diffs,\n             data_path,\n             gt_path,\n             ):\n\n    if not os.path.exists(data_path):\n        data_path = download_data(\"/\".join(data_path.split(\"/\")[:-1]))\n\n    xs = np.load(os.path.join(data_path, \"contrasts.npy\"))\n    data_high = {re.findall(\"high_(\\w+)\\.\", p)[0]: np.load(p) for p in glob(os.path.join(data_path, \"*\")) if \"high\" in p}\n    data_low = {re.findall(\"low_(\\w+)\\.\", p)[0]: np.load(p) for p in glob(os.path.join(data_path, \"*\")) if \"_low_\" in p}\n\n\n    f_mask = ['No mask', 'Theta_mask = 0', 'Theta_mask = 22.5', 'Theta_mask = 45', 'Theta_mask = 67.5', 'Theta_mask = 90', 'Theta_mask = 112.5', 'Theta_mask = 135']\n\n    diffs_high = defaultdict(dict)\n    for name, chroma in data_high.items():\n        for f, dat in zip(f_mask, chroma):\n            diffs_ = calculate_diffs(dat, dat[0:1])\n            diffs_high[name][f] = diffs_\n\n    diffs_low = defaultdict(dict)\n    for name, chroma in data_low.items():\n        for f, dat in zip(f_mask, chroma):\n            diffs_ = calculate_diffs(dat, dat[0:1])\n            diffs_low[name][f] = diffs_\n\n\n    diffs_low_s = np.array([a for a in diffs_low[\"achrom\"].values()])\n\n    order_corr = {}\n    order_corr[\"low\"] = calculate_spearman(diffs_low_s, ideal_ordering=[0,7,6,5,3,1,2,4])\n\n    diffs_high_s = np.array([a for a in diffs_high[\"achrom\"].values()])\n    order_corr[\"high\"] = calculate_spearman(diffs_high_s, ideal_ordering=[0,7,6,5,3,1,2,4])\n\n    return {\"correlations\":\n                {\"kendall\": order_corr}\n            }\n</code></pre>"},{"location":"api/#visturing.properties.jax.prop10.load_ground_truth","title":"<code>load_ground_truth(root_path='../../ground_truth_decalogo', return_freqs=False)</code>","text":"Source code in <code>visturing/properties/jax/prop10.py</code> <pre><code>def load_ground_truth(root_path: str = \"../../ground_truth_decalogo\", # Path to the root containing all the ground truth files\n                      return_freqs: bool = False, # Return the frequencies corresponding to each response\n                      ): # Tuple (x, y1, y2, y3)\n    data = sio.loadmat(os.path.join(root_path, \"responses_no_mask_achrom_1p5_3_6_12_24.mat\"))\n    data = data[\"resp_no_mask_achrom\"]\n    x, y = data[0], data[1:]\n    y_low, y_high = y[1], y[-2]\n    freqs = [3, 12]\n\n    if return_freqs:\n        return x, y_low, y_high, freqs\n    else:\n        return x, y_low, y_high\n</code></pre>"},{"location":"api/#visturing.properties.jax.prop10.plot_ground_truth","title":"<code>plot_ground_truth(x, y_low, y_high, freqs=(3, 12), figsize=(14, 4))</code>","text":"Source code in <code>visturing/properties/jax/prop10.py</code> <pre><code>def plot_ground_truth(x,\n                      y_low,\n                      y_high,\n                      freqs=(3, 12),\n                      figsize=(14,4),\n                      ): #\u00a0Returns both the fig and axes objects\n\n    fig, axes = plt.subplots(1,2, sharex=True, sharey=True, figsize=(10,4))\n    axes[0].plot(x, y_low, color=\"b\", label=f\"{freqs[0]} cpd\")\n    axes[1].plot(x, y_high, color=\"b\", label=f\"{freqs[1]} cpd\")\n    for ax in axes.ravel():\n        ax.legend()\n        ax.set_xlabel(\"Contrast\")\n    axes[0].set_ylabel(\"Visibility\")\n    return fig, axes\n</code></pre>"},{"location":"api/#visturing.properties.jax.prop2","title":"<code>prop2</code>","text":""},{"location":"api/#visturing.properties.jax.prop2.download_data","title":"<code>download_data(data_path)</code>","text":"Source code in <code>visturing/properties/jax/prop2.py</code> <pre><code>def download_data(data_path, # Path to download the data\n                  ):\n    # if not os.path.exists(data_path):\n    #     os.makedirs(data_path)\n    data_url = \"https://zenodo.org/records/17700252/files/Experiment_2.zip\"\n    path = wget.download(data_url)\n    with ZipFile(path) as zipObj:\n        zipObj.extractall(data_path)\n    os.remove(path)\n    return os.path.join(data_path, \"Experiment_2\")\n</code></pre>"},{"location":"api/#visturing.properties.jax.prop2.evaluate","title":"<code>evaluate(calculate_diffs, data_path='Data/Experiment_2', gt_path='ground_truth_decalogo')</code>","text":"Source code in <code>visturing/properties/jax/prop2.py</code> <pre><code>def evaluate(calculate_diffs,\n             data_path: str = \"Data/Experiment_2\",\n             gt_path: str = \"ground_truth_decalogo\",\n             ): # Tuple (responses, correlations)\n\n    if not os.path.exists(data_path):\n        data_path = download_data(\"/\".join(data_path.split(\"/\")[:-1]))\n\n    ##\u00a0Load ground truth\n    x_a_gt, y_a_gt, x_rg_gt, y_rg_gt, x_yb_gt, y_yb_gt = load_ground_truth(gt_path)\n\n    ## Load data\n    x_a, x_rg, x_yb = load_data(data_path)\n\n    data = {p.split(\"/\")[-1].split(\".\")[0]: np.load(p) for p in glob(os.path.join(data_path, \"*npy\")) if \"bgs\" not in p}\n    bgs = {p.split(\"/\")[-1].split(\".\")[0][4:]: np.load(p) for p in glob(os.path.join(data_path, \"*npy\")) if \"bgs\" in p}\n\n    diffs = {}\n    for c in [\"achrom\", \"red_green\", \"yellow_blue\"]:\n        diffs[c] = []\n        data_ = data[c]\n        bgs_ = bgs[c]\n        for cc, bg in zip(data_, bgs_):\n            diff = calculate_diffs(cc, bg[None,...])\n            diffs[c].append(diff)\n    diffs = {k: jnp.array(v) for k, v in diffs.items()}\n\n    ##\u00a0Calculate Order Correlation\n    spearman_correlations = {}\n\n    a, b, c, d = prepare_data(x_a, diffs[\"achrom\"], x_a_gt, y_a_gt)\n    spearman_correlations[\"achrom\"] = calculate_spearman(b, ideal_ordering=[0,1,2,3,4])\n\n    a, b_rg, c, d_rg = prepare_data(x_rg, diffs[\"red_green\"], x_rg_gt, y_rg_gt)\n    spearman_correlations[\"red_green\"] = calculate_spearman(b_rg, ideal_ordering=[0,1,2,3,4])\n\n    a, b_yb, c, d_yb = prepare_data(x_yb, diffs[\"yellow_blue\"], x_yb_gt, y_yb_gt)\n    spearman_correlations[\"yellow_blue\"] = calculate_spearman(b_yb, ideal_ordering=[0,1,2,3,4])\n\n    # Calculate Pearson\n    ## Achromatic\n\n    corr_achrom = pearson_correlation(\n        jnp.concatenate([\n            b[0].ravel(),\n        ]),\n        jnp.concatenate([\n            d.ravel(),\n        ])\n    )\n    ## Both Chromatics Together\n    corr_chroma = pearson_correlation(\n        jnp.concatenate([\n            b_rg[2].ravel(), b_yb[2].ravel(),\n        ]),\n        jnp.concatenate([\n            d_rg.ravel(), d_yb.ravel(),\n        ])\n    )\n    correlations = {\"pearson_achrom\": corr_achrom, \"pearson_chrom\": corr_chroma, \"kendall\": spearman_correlations}\n\n    return {\"diffs\": diffs, \"correlations\": correlations}\n</code></pre>"},{"location":"api/#visturing.properties.jax.prop2.load_data","title":"<code>load_data(data_path)</code>","text":"Source code in <code>visturing/properties/jax/prop2.py</code> <pre><code>def load_data(data_path):\n    x_a = np.load(os.path.join(data_path, \"luminancias.npy\"))\n    x_rg = np.load(os.path.join(data_path, \"x_rg.npy\"))\n    x_yb = np.load(os.path.join(data_path, \"x_yb.npy\"))\n    return x_a, x_rg, x_yb\n</code></pre>"},{"location":"api/#visturing.properties.jax.prop2.load_ground_truth","title":"<code>load_ground_truth(data_path='ground_truth_decalogo')</code>","text":"Source code in <code>visturing/properties/jax/prop2.py</code> <pre><code>def load_ground_truth(data_path: str = \"ground_truth_decalogo\", # Path to the root containing all the ground truth files\n                      ): # Tuple of tuples (x, y), (x_c, red-green), (x_c, yellow-blue)\n    data = sio.loadmat(os.path.join(data_path, \"weber.mat\"))\n    data = data[\"weber\"]\n\n    x = data[0]\n    y = data[1]\n\n    data = sio.loadmat(os.path.join(data_path, \"resp_RG.mat\"))\n    data = data[\"resp_RG\"]\n    x_c, rg, _ = data\n\n    data = sio.loadmat(os.path.join(data_path, \"resp_YB.mat\"))\n    data = data[\"resp_YB\"]\n    _, yb = data\n\n    return x, y, x_c, rg, x_c, yb\n</code></pre>"},{"location":"api/#visturing.properties.jax.prop2.load_images","title":"<code>load_images(data_path)</code>","text":"Source code in <code>visturing/properties/jax/prop2.py</code> <pre><code>def load_images(data_path):\n    data = {p.split(\"/\")[-1].split(\".\")[0]: np.load(p, allow_pickle=True) for p in glob(os.path.join(data_path, \"*npy\")) if \"bgs\" not in p and \"luminancias\" not in p and \"x_rg\" not in p and \"x_yb\" not in p}\n    bgs = {p.split(\"/\")[-1].split(\".\")[0][4:]: np.load(p, allow_pickle=True) for p in glob(os.path.join(data_path, \"*npy\")) if \"bgs\" in p}\n    return data, bgs\n</code></pre>"},{"location":"api/#visturing.properties.jax.prop2.plot_ground_truth","title":"<code>plot_ground_truth(x, y, x_c, rg, x_cc, yb)</code>","text":"Source code in <code>visturing/properties/jax/prop2.py</code> <pre><code>def plot_ground_truth(x,y,\n                      x_c, rg,\n                      x_cc, yb,\n                      ): #\u00a0Returns both the fig and axes objects\n    fig, axes = plt.subplots(1,3, figsize=(18,5))\n    axes[0].plot(x, y, \"b\")\n    axes[1].plot(x_c, rg, \"gray\")\n    axes[2].plot(x_c, yb, \"gray\")\n    for ax, name in zip(axes, [\"Achromatic\", \"Red-Green\", \"Yellow-Blue\"]): ax.set_title(name)\n    axes[0].set_xlabel(r\"Luminance (cd/m$^2$)\")\n    axes[1].set_xlabel(\"Linear RG\")\n    axes[2].set_xlabel(\"Linear YB\")\n    for ax, name in zip(axes, [\"Brightness\", \"Nonlinear RG\", \"Nonlinear YB\"]): ax.set_ylabel(name)\n    axes[1].set_xlim([-22,22])\n    axes[1].set_ylim([-8,8])\n    axes[2].set_xlim([-22,22])\n    axes[2].set_ylim([-8,8])\n    return fig, axes\n</code></pre>"},{"location":"api/#visturing.properties.jax.prop3_4","title":"<code>prop3_4</code>","text":""},{"location":"api/#visturing.properties.jax.prop3_4.download_data","title":"<code>download_data(data_path)</code>","text":"Source code in <code>visturing/properties/jax/prop3_4.py</code> <pre><code>def download_data(data_path, # Path to download the data\n                  ):\n    # if not os.path.exists(data_path):\n    #     os.makedirs(data_path)\n    data_url = \"https://zenodo.org/records/17700252/files/Experiment_3_4.zip\"\n    path = wget.download(data_url)\n    with ZipFile(path) as zipObj:\n        zipObj.extractall(data_path)\n    os.remove(path)\n    return os.path.join(data_path, \"Experiment_3_4\")\n</code></pre>"},{"location":"api/#visturing.properties.jax.prop3_4.evaluate","title":"<code>evaluate(calculate_diffs, data_path, gt_path)</code>","text":"Source code in <code>visturing/properties/jax/prop3_4.py</code> <pre><code>def evaluate(calculate_diffs,\n             data_path,\n             gt_path,\n             ):\n\n    if not os.path.exists(data_path):\n        data_path = download_data(\"/\".join(data_path.split(\"/\")[:-1]))\n\n    ## Load ground truth\n    x_gt, y_gt, rg_gt, yb_gt = load_ground_truth(gt_path)\n\n    ## Load data\n    noises = {p.split(\"/\")[-1].split(\".\")[0].split(\"_\")[-1]:np.load(p) for p in glob(os.path.join(data_path, \"*\")) if \"noises\" in p}\n    bg = np.load(os.path.join(data_path, \"background.npy\"))\n\n    ## Calculate the differences\n    diffs = {}\n    for k, noises_ in noises.items():\n        diffs_it = []\n        for noise_it in noises_:\n            diff = calculate_diffs(noise_it, bg[None,...])\n            # print(noise_it.shape, bg.shape, diff.shape)\n            diffs_it.append(diff)\n            # break\n        diffs_it = jnp.array(diffs_it)\n        diffs[k] = diffs_it.mean(axis=0)\n\n    gt_s = jnp.stack([y_gt,\n                    rg_gt,\n                    yb_gt])\n\n\n    diffs_s = jnp.stack([diffs[\"a\"],\n                        diffs[\"rg\"],\n                        diffs[\"yb\"]])\n\n    freqs = load_data(data_path)\n\n    bs, ds = [], []\n    for d, gt in zip(diffs_s, gt_s):\n        a, b, c, d = prepare_data(freqs, d, x_gt, gt)\n        bs.append(b)\n        ds.append(d)\n    b = jnp.array(bs)\n    d = jnp.array(ds)\n\n    order_corr = calculate_correlations_with_ground_truth(b, d)\n    pearson_corr = pearson_correlation(b.ravel(), d.ravel())\n\n    return {\"diffs_s\": diffs_s,\n            \"correlations\":\n                {\"pearson\": pearson_corr, \"kendall\": order_corr},\n            }\n</code></pre>"},{"location":"api/#visturing.properties.jax.prop3_4.evaluate_nodata","title":"<code>evaluate_nodata(calculate_diffs, freqs, bg, noises, x_gt, y_gt, rg_gt, yb_gt)</code>","text":"Source code in <code>visturing/properties/jax/prop3_4.py</code> <pre><code>def evaluate_nodata(calculate_diffs, freqs, bg, noises, x_gt, y_gt, rg_gt, yb_gt):\n\n    ## Calculate the differences\n    diffs = {}\n    for k, noises_ in noises.items():\n        diffs_it = []\n        for noise_it in noises_:\n            diff = calculate_diffs(noise_it, bg[None,...])\n            # print(noise_it.shape, bg.shape, diff.shape)\n            diffs_it.append(diff)\n            # break\n        diffs_it = jnp.array(diffs_it)\n        diffs[k] = diffs_it.mean(axis=0)\n\n    gt_s = jnp.stack([y_gt,\n                    rg_gt,\n                    yb_gt])\n\n\n    diffs_s = jnp.stack([diffs[\"a\"],\n                        diffs[\"rg\"],\n                        diffs[\"yb\"]])\n\n    bs, ds = [], []\n    for d, gt in zip(diffs_s, gt_s):\n        a, b, c, d = prepare_data(freqs, d, x_gt, gt)\n        bs.append(b)\n        ds.append(d)\n    b = jnp.array(bs)\n    d = jnp.array(ds)\n\n    order_corr = calculate_correlations_with_ground_truth(b, d)\n    pearson_corr = pearson_correlation(b.ravel(), d.ravel())\n\n    return {\"diffs_s\": diffs_s,\n            \"correlations\":\n                {\"pearson\": pearson_corr, \"kendall\": order_corr},\n            }\n</code></pre>"},{"location":"api/#visturing.properties.jax.prop3_4.load_data","title":"<code>load_data(root_path)</code>","text":"Source code in <code>visturing/properties/jax/prop3_4.py</code> <pre><code>def load_data(root_path: str):\n    freqs = np.load(os.path.join(root_path, \"freq.npy\"))\n    return freqs\n</code></pre>"},{"location":"api/#visturing.properties.jax.prop3_4.load_data_evaluate","title":"<code>load_data_evaluate(data_path, gt_path)</code>","text":"Source code in <code>visturing/properties/jax/prop3_4.py</code> <pre><code>def load_data_evaluate(data_path,\n                      gt_path,\n                      ):\n\n    if not os.path.exists(data_path):\n        data_path = download_data(\"/\".join(data_path.split(\"/\")[:-1]))\n\n    ## Load ground truth\n    x_gt, y_gt, rg_gt, yb_gt = load_ground_truth(gt_path)\n\n    ## Load data\n    noises = {p.split(\"/\")[-1].split(\".\")[0].split(\"_\")[-1]:np.load(p) for p in glob(os.path.join(data_path, \"*\")) if \"noises\" in p}\n    bg = np.load(os.path.join(data_path, \"background.npy\"))\n    freqs = load_data(data_path)\n    return freqs, bg, noises, x_gt, y_gt, rg_gt, yb_gt\n</code></pre>"},{"location":"api/#visturing.properties.jax.prop3_4.load_ground_truth","title":"<code>load_ground_truth(root_path='../../ground_truth_decalogo')</code>","text":"Source code in <code>visturing/properties/jax/prop3_4.py</code> <pre><code>def load_ground_truth(root_path: str = \"../../ground_truth_decalogo\", # Path to the root containing all the ground truth files\n                      ): # Tuple (x, y, red-green, yellow-blue)\n    data = sio.loadmat(os.path.join(root_path, \"responses_CSF_achrom.mat\"))\n    data = data[\"CSF_achrom\"]\n    x, y = data\n    data = sio.loadmat(os.path.join(root_path, \"responses_CSF_RG.mat\"))\n    data = data[\"CSF_RG\"]\n    _, rg = data\n    data = sio.loadmat(os.path.join(root_path, \"responses_CSF_YB.mat\"))\n    data = data[\"CSF_YB\"]\n    _, yb = data\n    return x, y, rg, yb\n</code></pre>"},{"location":"api/#visturing.properties.jax.prop3_4.plot_ground_truth","title":"<code>plot_ground_truth(x, y, rg, yb)</code>","text":"Source code in <code>visturing/properties/jax/prop3_4.py</code> <pre><code>def plot_ground_truth(x,\n                      y,\n                      rg,\n                      yb,\n                      ): #\u00a0Returns both the fig and axes objects\n    fig, axes = plt.subplots()\n    axes.plot(x, y, \"k\", label=\"Achromatic\")\n    axes.plot(x, rg, \"r\", label=\"Red-Green\")\n    axes.plot(x, yb, \"b\", label=\"Yellow-Blue\")\n    axes.set_xscale(\"log\")\n    axes.set_yscale(\"log\")\n    axes.set_xlim([1,32])\n    axes.set_ylim(bottom=0.3)\n    axes.legend()\n    axes.set_xlabel(\"Frequency (cpd)\")\n    axes.set_ylabel(\"Sensitivity\")\n    return fig, axes\n</code></pre>"},{"location":"api/#visturing.properties.jax.prop5","title":"<code>prop5</code>","text":""},{"location":"api/#visturing.properties.jax.prop5.download_data","title":"<code>download_data(data_path)</code>","text":"Source code in <code>visturing/properties/jax/prop5.py</code> <pre><code>def download_data(data_path, # Path to download the data\n                  ):\n    # if not os.path.exists(data_path):\n    #     os.makedirs(data_path)\n    data_url = \"https://zenodo.org/records/17700252/files/Experiment_5.zip\"\n    path = wget.download(data_url)\n    with ZipFile(path) as zipObj:\n        zipObj.extractall(data_path)\n    os.remove(path)\n    return os.path.join(data_path, \"Experiment_5\")\n</code></pre>"},{"location":"api/#visturing.properties.jax.prop5.evaluate","title":"<code>evaluate(calculate_diffs, data_path, gt_path)</code>","text":"Source code in <code>visturing/properties/jax/prop5.py</code> <pre><code>def evaluate(calculate_diffs,\n             data_path,\n             gt_path,\n             ):\n\n    if not os.path.exists(data_path):\n        data_path = download_data(\"/\".join(data_path.split(\"/\")[:-1]))\n\n    x_gt, y1_gt, y2_gt, y3_gt = load_ground_truth(gt_path)\n\n    noises = {p.split(\"/\")[-1].split(\".\")[0].split(\"_\")[-1]: np.load(p) for p in glob(os.path.join(data_path, \"*npy\")) if \"noises\" in p}\n    bgs = {p.split(\"/\")[-1].split(\".\")[0].split(\"_\")[-1]: np.load(p) for p in glob(os.path.join(data_path, \"*npy\")) if \"background\" in p}\n    freqs = np.load(os.path.join(data_path, \"freqs.npy\"))\n\n\n    diffs = {}\n    for k, noise in noises.items():\n        bg = bgs[k][None,...]\n        diffs_it = []\n        for noise_it in noise:\n            diff = calculate_diffs(noise_it, bg)\n            # print(noise_it.shape, bg.shape, diff.shape)\n            diffs_it.append(diff)\n            # break\n        diffs_it = jnp.array(diffs_it)\n        diffs[k] = diffs_it.mean(axis=0)\n        # break\n\n    diffs_a = diffs.pop(\"a\")\n    diffs_inv = {k:diffs_a/(v+1e-6) for k, v in diffs.items()}\n    diffs_inv = {k:(v-1) for k, v in diffs_inv.items()}\n    diffs_inv = {k:jnp.clip(v, a_min=1e-6) for k, v in diffs_inv.items()}\n    diffs_inv = {k:v/v.max() for k, v in diffs_inv.items()}\n\n    k = list(diffs_inv.keys())[0]\n    a, b, c, d1 = prepare_data(freqs[1:], diffs_inv[k][1:], x_gt, y1_gt)\n    a, b, c, d2 = prepare_data(freqs[1:], diffs_inv[k][1:], x_gt, y2_gt)\n    a, b, c, d3 = prepare_data(freqs[1:], diffs_inv[k][1:], x_gt, y3_gt)\n\n\n    diffs_stack = jnp.stack([diffs_inv[\"3\"][1:],\n                            diffs_inv[\"6\"][1:],\n                            diffs_inv[\"12\"][1:]])\n    ds = jnp.stack([d1, d2, d3])\n\n    order_corr = calculate_correlations_with_ground_truth(diffs_stack, ds)\n    pearson_corr = pearson_correlation(diffs_stack.ravel(), ds.ravel())\n\n    return {\"ds\": ds,\n            \"diffs\": diffs_stack,\n            \"correlations\":\n                {\"pearson\": pearson_corr, \"kendall\": order_corr},\n            }\n</code></pre>"},{"location":"api/#visturing.properties.jax.prop5.evaluate_nodata","title":"<code>evaluate_nodata(calculate_diffs, x_gt, y1_gt, y2_gt, y3_gt, noises, bgs, freqs)</code>","text":"Source code in <code>visturing/properties/jax/prop5.py</code> <pre><code>def evaluate_nodata(calculate_diffs,\n                    x_gt, y1_gt, y2_gt, y3_gt,\n                    noises, bgs, freqs,\n                    ):\n\n    diffs = {}\n    for k, noise in noises.items():\n        bg = bgs[k][None,...]\n        diffs_it = []\n        for noise_it in noise:\n            diff = calculate_diffs(noise_it, bg)\n            diffs_it.append(diff)\n            # break\n        diffs_it = jnp.array(diffs_it)\n        diffs[k] = diffs_it.mean(axis=0)\n        # break\n\n    diffs_a = diffs.pop(\"a\")\n    # print(diffs)\n    diffs_inv = {k:diffs_a/(v+1e-6) for k, v in diffs.items()}\n    diffs_inv = {k:(v-1) for k, v in diffs_inv.items()}\n    # diffs_inv = {k:jnp.clip(v, a_min=1e-6) for k, v in diffs_inv.items()}\n    # diffs_inv = {k:jax.nn.softplus(v) for k, v in diffs_inv.items()}\n    diffs_inv = {k:v/v.max() for k, v in diffs_inv.items()}\n\n    k = list(diffs_inv.keys())[0]\n    a, b, c, d1 = prepare_data(freqs[1:], diffs_inv[k][1:], x_gt, y1_gt)\n    a, b, c, d2 = prepare_data(freqs[1:], diffs_inv[k][1:], x_gt, y2_gt)\n    a, b, c, d3 = prepare_data(freqs[1:], diffs_inv[k][1:], x_gt, y3_gt)\n\n\n    diffs_stack = jnp.stack([diffs_inv[\"3\"][1:],\n                            diffs_inv[\"6\"][1:],\n                            diffs_inv[\"12\"][1:]])\n    ds = jnp.stack([d1, d2, d3])\n\n    order_corr = calculate_correlations_with_ground_truth(diffs_stack, ds)\n    pearson_corr = pearson_correlation(diffs_stack.ravel(), ds.ravel())\n\n    return {\"ds\": ds,\n            \"diffs\": diffs_stack,\n            \"correlations\":\n                {\"pearson\": pearson_corr, \"kendall\": order_corr},\n            }\n</code></pre>"},{"location":"api/#visturing.properties.jax.prop5.get_evaluate_data","title":"<code>get_evaluate_data(data_path, gt_path)</code>","text":"Source code in <code>visturing/properties/jax/prop5.py</code> <pre><code>def get_evaluate_data(data_path,\n                      gt_path,\n                      ):\n    if not os.path.exists(data_path):\n        data_path = download_data(\"/\".join(data_path.split(\"/\")[:-1]))\n\n    x_gt, y1_gt, y2_gt, y3_gt = load_ground_truth(gt_path)\n\n    noises = {p.split(\"/\")[-1].split(\".\")[0].split(\"_\")[-1]: np.load(p) for p in glob(os.path.join(data_path, \"*npy\")) if \"noises\" in p}\n    bgs = {p.split(\"/\")[-1].split(\".\")[0].split(\"_\")[-1]: np.load(p) for p in glob(os.path.join(data_path, \"*npy\")) if \"background\" in p}\n    freqs = np.load(os.path.join(data_path, \"freqs.npy\"))\n    return x_gt, y1_gt, y2_gt, y3_gt, noises, bgs, freqs\n</code></pre>"},{"location":"api/#visturing.properties.jax.prop5.load_ground_truth","title":"<code>load_ground_truth(root_path='../../ground_truth_decalogo')</code>","text":"Source code in <code>visturing/properties/jax/prop5.py</code> <pre><code>def load_ground_truth(root_path: str = \"../../ground_truth_decalogo\", # Path to the root containing all the ground truth files\n                      ): # Tuple (x, y1, y2, y3)\n    data = sio.loadmat(os.path.join(root_path, \"Campbell_Blakemore.mat\"))\n    data = data[\"Campbell_Blakemore\"]\n    x, y1, y2, y3 = data\n    return x, y1, y2, y3\n</code></pre>"},{"location":"api/#visturing.properties.jax.prop5.plot_ground_truth","title":"<code>plot_ground_truth(x, y1, y2, y3)</code>","text":"Source code in <code>visturing/properties/jax/prop5.py</code> <pre><code>def plot_ground_truth(x,\n                      y1,\n                      y2,\n                      y3,\n                      ): #\u00a0Returns both the fig and axes objects\n    fig, axes = plt.subplots()\n    axes.plot(x, y1, \"k\", linestyle=\"-\", label=\"3 cpd\")\n    axes.plot(x, y2, \"k\", linestyle=\":\", label=\"6 cpd\")\n    axes.plot(x, y3, \"k\", linestyle=\"-.\", label=\"12 cpd\")\n    axes.set_xlabel(\"Frequency (cpd)\")\n    axes.set_xscale(\"log\")\n    axes.set_xlim([1,32])\n    axes.legend()\n    return fig, axes\n</code></pre>"},{"location":"api/#visturing.properties.jax.prop6_7","title":"<code>prop6_7</code>","text":""},{"location":"api/#visturing.properties.jax.prop6_7.download_data","title":"<code>download_data(data_path)</code>","text":"Source code in <code>visturing/properties/jax/prop6_7.py</code> <pre><code>def download_data(data_path, # Path to download the data\n                  ):\n    # if not os.path.exists(data_path):\n    #     os.makedirs(data_path)\n    data_url = \"https://zenodo.org/records/17700252/files/Experiment_6_7.zip\"\n    path = wget.download(data_url)\n    with ZipFile(path) as zipObj:\n        zipObj.extractall(data_path)\n    os.remove(path)\n    return os.path.join(data_path, \"Experiment_6_7\")\n</code></pre>"},{"location":"api/#visturing.properties.jax.prop6_7.evaluate","title":"<code>evaluate(calculate_diffs, data_path, gt_path)</code>","text":"Source code in <code>visturing/properties/jax/prop6_7.py</code> <pre><code>def evaluate(calculate_diffs,\n             data_path,\n             gt_path,\n             ):\n\n    if not os.path.exists(data_path):\n        data_path = download_data(\"/\".join(data_path.split(\"/\")[:-1]))\n\n    x_gt, y_gt, rg_gt, yb_gt = load_ground_truth(gt_path)\n    data = {re.findall(\"noise_(\\w+)\\.\", p)[0]: np.load(p) for p in glob(os.path.join(data_path, \"*\")) if \"gabor\" in p}\n    freqs = np.array([1.5, 3, 6, 12, 24])\n\n    diffs = defaultdict(dict)\n    for name, chroma in data.items():\n        for f, dat in zip(freqs, chroma):\n            diffs_ = calculate_diffs(dat, dat[0:1])\n            diffs[name][f] = diffs_\n\n    x_a, x_rg, x_yb = load_data(data_path)\n\n    diffs_a = jnp.array([a for a in diffs[\"achrom\"].values()])\n    diffs_rg = jnp.array([a for a in diffs[\"red_green\"].values()])\n    diffs_yb = jnp.array([a for a in diffs[\"yellow_blue\"].values()])\n\n    bs, ds = [], []\n    for b, d in zip(diffs_a, y_gt):\n        a, b, c, d = prepare_data(x_a, b, x_gt, d)\n        bs.append(b)\n        ds.append(d)\n    b_a = jnp.array(bs)\n    d_a = jnp.array(ds)\n\n    order_corr = {}\n    order_corr[\"achrom\"] = calculate_correlations_with_ground_truth(b_a, d_a)\n\n    bs, ds = [], []\n    for b, d in zip(diffs_rg, rg_gt):\n        a, b, c, d = prepare_data(x_rg, b, x_gt, d)\n        bs.append(b)\n        ds.append(d)\n    b_rg = jnp.array(bs)\n    d_rg = jnp.array(ds)\n\n\n    order_corr[\"red_green\"] = calculate_correlations_with_ground_truth(b_rg, d_rg)\n\n\n    bs, ds = [], []\n    for b, d in zip(diffs_yb, yb_gt):\n        a, b, c, d = prepare_data(x_yb, b, x_gt, d)\n        bs.append(b)\n        ds.append(d)\n    b_yb = jnp.array(bs)\n    d_yb = jnp.array(ds)\n\n\n    order_corr[\"yellow_blue\"] = calculate_correlations_with_ground_truth(b_yb, d_yb)\n\n\n    b_cat = jnp.concatenate([\n            b_a.ravel(), b_rg.ravel(), b_yb.ravel(),\n        ])\n    nan_mask = jnp.isnan(b_cat)\n    d_cat = jnp.concatenate([\n            d_a.ravel(), d_rg.ravel(), d_yb.ravel(),\n        ])\n    pearson = pearson_correlation(\n        b_cat[~nan_mask], d_cat[~nan_mask]\n    )\n\n    return {\"correlations\":\n                {\"kendall\": order_corr, \"pearson\": pearson}\n            }\n</code></pre>"},{"location":"api/#visturing.properties.jax.prop6_7.load_data","title":"<code>load_data(root_path)</code>","text":"Source code in <code>visturing/properties/jax/prop6_7.py</code> <pre><code>def load_data(root_path):\n    c_a = np.load(os.path.join(root_path, \"contrast_a.npy\"))\n    c_rg = np.load(os.path.join(root_path, \"contrast_rg.npy\"))\n    c_yb = np.load(os.path.join(root_path, \"contrast_yb.npy\"))\n    return c_a, c_rg, c_yb\n</code></pre>"},{"location":"api/#visturing.properties.jax.prop6_7.load_ground_truth","title":"<code>load_ground_truth(root_path='../../ground_truth_decalogo')</code>","text":"Source code in <code>visturing/properties/jax/prop6_7.py</code> <pre><code>def load_ground_truth(root_path: str = \"../../ground_truth_decalogo\", # Path to the root containing all the ground truth files\n                      ): # Tuple (x, y, y_rg, y_yb)\n    data = sio.loadmat(os.path.join(root_path, \"responses_no_mask_achrom_1p5_3_6_12_24.mat\"))\n    data = data[\"resp_no_mask_achrom\"]\n    x, y = data[0], data[1:]\n\n    data = sio.loadmat(os.path.join(root_path, \"responses_no_mask_RG_1p5_3_6_12_24.mat\"))\n    data = data[\"resp_no_mask_RG\"]\n    x, y_rg = data[0], data[1:]\n\n    data = sio.loadmat(os.path.join(root_path, \"responses_no_mask_YB_1p5_3_6_12_24.mat\"))\n    data = data[\"resp_no_mask_YB\"]\n    x, y_yb = data[0], data[1:]\n\n    return x, y, y_rg, y_yb\n</code></pre>"},{"location":"api/#visturing.properties.jax.prop6_7.plot_ground_truth","title":"<code>plot_ground_truth(x, y, y_rg, y_yb, figsize=(14, 4))</code>","text":"Source code in <code>visturing/properties/jax/prop6_7.py</code> <pre><code>def plot_ground_truth(x,\n                      y,\n                      y_rg,\n                      y_yb,\n                      figsize=(14,4),\n                      ): #\u00a0Returns both the fig and axes objects\n    freqs = [1.5, 3, 6, 12, 24]\n    colors = [\"lightgray\", \"black\", \"blue\", \"gray\", \"red\"]\n    colors_rg = [\"blue\", \"black\", \"gray\", \"lightgray\", \"red\"]\n    colors_yb = [\"blue\", \"black\", \"gray\", \"lightgray\", \"red\"]\n\n    fig, axes = plt.subplots(1,3, figsize=figsize, sharex=True, sharey=True)\n    for y_, f, c in zip(y, freqs, colors):\n        axes[0].plot(x, y_, color=c, label=f\"Freq {f}\")\n    for y_, f, c in zip(y_rg, freqs, colors_rg):\n        axes[1].plot(x, y_, color=c, label=f\"Freq {f}\")\n    for y_, f, c in zip(y_yb, freqs, colors_yb):\n        axes[2].plot(x, y_, color=c, label=f\"Freq {f}\")\n    axes[0].set_ylabel(\"Visibility\")\n    for ax in axes.ravel():\n        ax.set_xlabel(\"Contrast\")\n        ax.legend()\n    return fig, axes\n</code></pre>"},{"location":"api/#visturing.properties.jax.prop8","title":"<code>prop8</code>","text":""},{"location":"api/#visturing.properties.jax.prop8.download_data","title":"<code>download_data(data_path)</code>","text":"Source code in <code>visturing/properties/jax/prop8.py</code> <pre><code>def download_data(data_path, # Path to download the data\n                  ):\n    # if not os.path.exists(data_path):\n    #     os.makedirs(data_path)\n    data_url = \"https://zenodo.org/records/17700252/files/Experiment_8.zip\"\n    path = wget.download(data_url)\n    with ZipFile(path) as zipObj:\n        zipObj.extractall(data_path)\n    os.remove(path)\n    return os.path.join(data_path, \"Experiment_8\")\n</code></pre>"},{"location":"api/#visturing.properties.jax.prop8.evaluate","title":"<code>evaluate(calculate_diffs, data_path, gt_path)</code>","text":"Source code in <code>visturing/properties/jax/prop8.py</code> <pre><code>def evaluate(calculate_diffs,\n             data_path,\n             gt_path,\n             ):\n\n    if not os.path.exists(data_path):\n        data_path = download_data(\"/\".join(data_path.split(\"/\")[:-1]))\n\n    xs = np.load(os.path.join(data_path, \"contrasts.npy\"))\n    data_high = {re.findall(\"high_(\\w+)\\.\", p)[0]: np.load(p) for p in glob(os.path.join(data_path, \"*\")) if \"high\" in p}\n    data_low = {re.findall(\"low_(\\w+)\\.\", p)[0]: np.load(p) for p in glob(os.path.join(data_path, \"*\")) if \"_low_\" in p}\n\n\n    c_mask = ['No mask', 'C_mask = 0.075', 'C_mask = 0.150', 'C_mask = 0.225', 'C_mask = 0.300']\n\n    diffs_high = defaultdict(dict)\n    for name, chroma in data_high.items():\n        for f, dat in zip(c_mask, chroma):\n            diffs_ = calculate_diffs(dat, dat[0:1])\n            diffs_high[name][f] = diffs_\n\n    diffs_low = defaultdict(dict)\n    for name, chroma in data_low.items():\n        for f, dat in zip(c_mask, chroma):\n            diffs_ = calculate_diffs(dat, dat[0:1])\n            diffs_low[name][f] = diffs_\n\n\n    x_gt, y_low_gt, y_high_gt  = load_ground_truth(gt_path)\n\n\n    diffs_low_a_s = jnp.array([a for a in diffs_low[\"achrom\"].values()])\n    diffs_low_rg_s = jnp.array([a for a in diffs_low[\"red_green\"].values()])\n    diffs_low_yb_s = jnp.array([a for a in diffs_low[\"yellow_blue\"].values()])\n\n\n    bs = []\n    for b in diffs_low_a_s:\n        a, b, c, d = prepare_data(xs, b, x_gt, y_low_gt)\n        bs.append(b)\n    b_low = jnp.array(bs)\n\n    order_corr = {}\n    order_corr[\"low\"] = calculate_spearman(b_low, ideal_ordering=[0,1,2,3,4])\n\n\n    diffs_high_a_s = jnp.array([a for a in diffs_high[\"achrom\"].values()])\n\n    bs = []\n    for b in diffs_high_a_s:\n        a, b, c, d = prepare_data(xs, b, x_gt, y_high_gt)\n        bs.append(b)\n    b_high = jnp.array(bs)\n\n    order_corr[\"high\"] = calculate_spearman(b_high, ideal_ordering=[0,1,2,3,4])\n\n    pearson = pearson_correlation(\n        jnp.concatenate([\n            b_low[0], b_high[0]\n        ]),\n        jnp.concatenate([\n            y_low_gt, y_high_gt\n        ])\n    )\n\n    return {\"correlations\":\n                {\"kendall\": order_corr, \"pearson\": pearson}\n            }\n</code></pre>"},{"location":"api/#visturing.properties.jax.prop8.load_ground_truth","title":"<code>load_ground_truth(root_path='../../ground_truth_decalogo', return_freqs=False)</code>","text":"Source code in <code>visturing/properties/jax/prop8.py</code> <pre><code>def load_ground_truth(root_path: str = \"../../ground_truth_decalogo\", # Path to the root containing all the ground truth files\n                      return_freqs: bool = False, # Return the frequencies corresponding to each response\n                      ): # Tuple (x, y1, y2, y3)\n    data = sio.loadmat(os.path.join(root_path, \"responses_no_mask_achrom_1p5_3_6_12_24.mat\"))\n    data = data[\"resp_no_mask_achrom\"]\n    x, y = data[0], data[1:]\n    y_low, y_high = y[1], y[-2]\n    freqs = [3, 12]\n\n    if return_freqs:\n        return x, y_low, y_high, freqs\n    else:\n        return x, y_low, y_high\n</code></pre>"},{"location":"api/#visturing.properties.jax.prop8.plot_ground_truth","title":"<code>plot_ground_truth(x, y_low, y_high, freqs=(3, 12), figsize=(14, 4))</code>","text":"Source code in <code>visturing/properties/jax/prop8.py</code> <pre><code>def plot_ground_truth(x,\n                      y_low,\n                      y_high,\n                      freqs=(3, 12),\n                      figsize=(14,4),\n                      ): #\u00a0Returns both the fig and axes objects\n\n    fig, axes = plt.subplots(1,2, sharex=True, sharey=True, figsize=(10,4))\n    axes[0].plot(x, y_low, color=\"b\", label=f\"{freqs[0]} cpd\")\n    axes[1].plot(x, y_high, color=\"b\", label=f\"{freqs[1]} cpd\")\n    for ax in axes.ravel():\n        ax.legend()\n        ax.set_xlabel(\"Contrast\")\n    axes[0].set_ylabel(\"Visibility\")\n    return fig, axes\n</code></pre>"},{"location":"api/#visturing.properties.jax.prop9","title":"<code>prop9</code>","text":""},{"location":"api/#visturing.properties.jax.prop9.download_data","title":"<code>download_data(data_path)</code>","text":"Source code in <code>visturing/properties/jax/prop9.py</code> <pre><code>def download_data(data_path, # Path to download the data\n                  ):\n    # if not os.path.exists(data_path):\n    #     os.makedirs(data_path)\n    data_url = \"https://zenodo.org/records/17700252/files/Experiment_9.zip\"\n    path = wget.download(data_url)\n    with ZipFile(path) as zipObj:\n        zipObj.extractall(data_path)\n    os.remove(path)\n    return os.path.join(data_path, \"Experiment_9\")\n</code></pre>"},{"location":"api/#visturing.properties.jax.prop9.evaluate","title":"<code>evaluate(calculate_diffs, data_path, gt_path)</code>","text":"Source code in <code>visturing/properties/jax/prop9.py</code> <pre><code>def evaluate(calculate_diffs,\n             data_path,\n             gt_path,\n             ):\n\n    if not os.path.exists(data_path):\n        data_path = download_data(\"/\".join(data_path.split(\"/\")[:-1]))\n\n    xs = np.load(os.path.join(data_path, \"contrasts.npy\"))\n    data_high = {re.findall(\"high_(\\w+)\\.\", p)[0]: np.load(p) for p in glob(os.path.join(data_path, \"*\")) if \"high\" in p}\n    data_low = {re.findall(\"low_(\\w+)\\.\", p)[0]: np.load(p) for p in glob(os.path.join(data_path, \"*\")) if \"_low_\" in p}\n\n\n    f_mask = ['No mask', 'F_mask = 1.5 cpd', 'F_mask = 3 cpd', 'F_mask = 6 cpd', 'F_mask = 12 cpd', 'F_mask = 24 cpd']\n\n    diffs_high = defaultdict(dict)\n    for name, chroma in data_high.items():\n        for f, dat in zip(f_mask, chroma):\n            diffs_ = calculate_diffs(dat, dat[0:1])\n            diffs_high[name][f] = diffs_\n\n    diffs_low = defaultdict(dict)\n    for name, chroma in data_low.items():\n        for f, dat in zip(f_mask, chroma):\n            diffs_ = calculate_diffs(dat, dat[0:1])\n            diffs_low[name][f] = diffs_\n\n\n    diffs_low_s = np.array([a for a in diffs_low[\"achrom\"].values()])\n\n    order_corr = {}\n    order_corr[\"low\"] = calculate_spearman(diffs_low_s, ideal_ordering=[0,4,5,3,2,1])\n\n    diffs_high_s = np.array([a for a in diffs_high[\"achrom\"].values()])\n\n    order_corr[\"high\"] = calculate_spearman(diffs_high_s, ideal_ordering=[0,1,2,3,5,4])\n    return {\"correlations\":\n                {\"kendall\": order_corr}\n            }\n</code></pre>"},{"location":"api/#visturing.properties.jax.prop9.load_ground_truth","title":"<code>load_ground_truth(root_path='../../ground_truth_decalogo', return_freqs=False)</code>","text":"Source code in <code>visturing/properties/jax/prop9.py</code> <pre><code>def load_ground_truth(root_path: str = \"../../ground_truth_decalogo\", # Path to the root containing all the ground truth files\n                      return_freqs: bool = False, # Return the frequencies corresponding to each response\n                      ): # Tuple (x, y1, y2, y3)\n    data = sio.loadmat(os.path.join(root_path, \"responses_no_mask_achrom_1p5_3_6_12_24.mat\"))\n    data = data[\"resp_no_mask_achrom\"]\n    x, y = data[0], data[1:]\n    y_low, y_high = y[1], y[-2]\n    freqs = [3, 12]\n\n    if return_freqs:\n        return x, y_low, y_high, freqs\n    else:\n        return x, y_low, y_high\n</code></pre>"},{"location":"api/#visturing.properties.jax.prop9.plot_ground_truth","title":"<code>plot_ground_truth(x, y_low, y_high, freqs=(3, 12), figsize=(14, 4))</code>","text":"Source code in <code>visturing/properties/jax/prop9.py</code> <pre><code>def plot_ground_truth(x,\n                      y_low,\n                      y_high,\n                      freqs=(3, 12),\n                      figsize=(14,4),\n                      ): #\u00a0Returns both the fig and axes objects\n\n    fig, axes = plt.subplots(1,2, sharex=True, sharey=True, figsize=(10,4))\n    axes[0].plot(x, y_low, color=\"b\", label=f\"{freqs[0]} cpd\")\n    axes[1].plot(x, y_high, color=\"b\", label=f\"{freqs[1]} cpd\")\n    for ax in axes.ravel():\n        ax.legend()\n        ax.set_xlabel(\"Contrast\")\n    axes[0].set_ylabel(\"Visibility\")\n    return fig, axes\n</code></pre>"},{"location":"api/#visturing.properties.jax.ranking","title":"<code>ranking</code>","text":""},{"location":"api/#visturing.properties.jax.ranking.calculate_correlations","title":"<code>calculate_correlations(ground_truth, experimental)</code>","text":"Source code in <code>visturing/properties/jax/ranking.py</code> <pre><code>def calculate_correlations(ground_truth, experimental):\n    return {\n        # \"spearman\": stats.spearmanr(ground_truth.ravel(),\n        #                             experimental.ravel())[0],\n        \"kendall\": kendall_correlation(ground_truth.ravel(),\n                                       experimental.ravel()),\n        # \"pearson\": stats.pearsonr(ground_truth.ravel(),\n        #                             experimental.ravel())[0],\n    }\n</code></pre>"},{"location":"api/#visturing.properties.jax.ranking.calculate_correlations_with_ground_truth","title":"<code>calculate_correlations_with_ground_truth(experimental_curve, ground_truth)</code>","text":"Source code in <code>visturing/properties/jax/ranking.py</code> <pre><code>def calculate_correlations_with_ground_truth(experimental_curve, ground_truth):\n    gt_ordering = (-ground_truth).argsort(axis=0)\n    e_ordering = (-experimental_curve).argsort(axis=0)\n    return calculate_correlations(gt_ordering.ravel(), e_ordering.ravel())\n</code></pre>"},{"location":"api/#visturing.properties.jax.ranking.calculate_pearson_stack","title":"<code>calculate_pearson_stack(s1, s2)</code>","text":"Source code in <code>visturing/properties/jax/ranking.py</code> <pre><code>def calculate_pearson_stack(s1, s2):\n    return stats.pearsonr(s1.ravel(), s2.ravel())\n</code></pre>"},{"location":"api/#visturing.properties.jax.ranking.calculate_spearman","title":"<code>calculate_spearman(experimental_curve, ideal_ordering)</code>","text":"Source code in <code>visturing/properties/jax/ranking.py</code> <pre><code>def calculate_spearman(experimental_curve, ideal_ordering):\n    ordered_curves = (-experimental_curve).argsort(axis=0)\n    ideal_ordering = jnp.array(ideal_ordering)[:,None].repeat(ordered_curves.shape[1], axis=1)\n    return calculate_correlations(ordered_curves, ideal_ordering)\n</code></pre>"},{"location":"api/#visturing.properties.jax.ranking.compare_ranges","title":"<code>compare_ranges(x1, x2)</code>","text":"Source code in <code>visturing/properties/jax/ranking.py</code> <pre><code>def compare_ranges(x1, x2):\n    m, M = False, False\n    if x1.min() &lt;= x2.min():\n        m = True\n    if x1.max() &gt;= x2.max():\n        M = True\n    return all((m, M))\n</code></pre>"},{"location":"api/#visturing.properties.jax.ranking.prepare_and_correlate","title":"<code>prepare_and_correlate(x_e, y_e, x_gt, y_gt)</code>","text":"Source code in <code>visturing/properties/jax/ranking.py</code> <pre><code>def prepare_and_correlate(x_e, y_e, x_gt, y_gt):\n    x_e, y_e, x_gt, y_gt = prepare_data(x_e, y_e, x_gt, y_gt)\n    return calculate_correlations(y_e, y_gt)\n</code></pre>"},{"location":"api/#visturing.properties.jax.ranking.prepare_and_correlate_order","title":"<code>prepare_and_correlate_order(x_e, y_e, x_gt, y_gt)</code>","text":"Source code in <code>visturing/properties/jax/ranking.py</code> <pre><code>def prepare_and_correlate_order(x_e, y_e, x_gt, y_gt):\n    x_e, y_e, x_gt, y_gt = prepare_data(x_e, y_e, x_gt, y_gt)\n    return calculate_correlations_with_ground_truth(y_e, y_gt)\n</code></pre>"},{"location":"api/#visturing.properties.jax.ranking.prepare_data","title":"<code>prepare_data(x_e, y_e, x_gt, y_gt)</code>","text":"<p>Prepares the data to be compared via correlations.</p> Source code in <code>visturing/properties/jax/ranking.py</code> <pre><code>def prepare_data(x_e, y_e, x_gt, y_gt):\n    \"\"\"Prepares the data to be compared via correlations.\"\"\"\n    if gt_shorter:=compare_ranges(x_e, x_gt):\n        x_wider = x_e\n        y_wider = y_e\n        x_shorter = x_gt\n        y_shorter = y_gt\n    else:\n        x_wider = x_gt\n        y_wider = y_gt\n        x_shorter = x_e\n        y_shorter = y_e\n\n    # print(x_wider.shape, y_wider.shape, x_shorter.shape, y_shorter.shape)\n    # if len(y_wider) &gt; 1:\n    #     y_wider_interp = np.array([np.interp(x_shorter, x_wider, row) for row in y_wider])\n    # else:\n    #     y_wider_interp = np.interp(x_shorter, x_wider, y_wider)\n    y_wider_interp = jnp.interp(x_shorter, x_wider, y_wider)\n    if gt_shorter:\n        return x_shorter, y_wider_interp, x_shorter, y_shorter\n    else:\n        return x_shorter, y_shorter, x_shorter, y_wider_interp\n</code></pre>"},{"location":"api/#visturing.properties.jax.utils","title":"<code>utils</code>","text":""},{"location":"api/#visturing.properties.jax.utils.evaluate_all","title":"<code>evaluate_all(calculate_diffs, data_path, gt_path)</code>","text":"Source code in <code>visturing/properties/jax/utils.py</code> <pre><code>def evaluate_all(calculate_diffs,\n                 data_path, # Path to the root directory\n                 gt_path, #\u00a0Path to the ground truth\n                 ):\n\n    if not os.path.exists(gt_path):\n        gt_path = download_ground_truth(\"/\".join(gt_path.split(\"/\")[:-1]))\n\n    results = {}\n    results[\"prop1\"] = prop1.evaluate(calculate_diffs, os.path.join(data_path, \"Experiment_1\"), gt_path)\n    results[\"prop2\"] = prop2.evaluate(calculate_diffs, os.path.join(data_path, \"Experiment_2\"), gt_path)\n    results[\"prop3_4\"] = prop3_4.evaluate(calculate_diffs, os.path.join(data_path, \"Experiment_3_4\"), gt_path)\n    results[\"prop5\"] = prop5.evaluate(calculate_diffs, os.path.join(data_path, \"Experiment_5\"), gt_path)\n    results[\"prop6_7\"] = prop6_7.evaluate(calculate_diffs, os.path.join(data_path, \"Experiment_6_7\"), gt_path)\n    results[\"prop8\"] = prop8.evaluate(calculate_diffs, os.path.join(data_path, \"Experiment_8\"), gt_path)\n    results[\"prop9\"] = prop9.evaluate(calculate_diffs, os.path.join(data_path, \"Experiment_9\"), gt_path)\n    results[\"prop10\"] = prop10.evaluate(calculate_diffs, os.path.join(data_path, \"Experiment_10\"), gt_path)\n\n    return results\n</code></pre>"},{"location":"api/#visturing.properties.prop1","title":"<code>prop1</code>","text":""},{"location":"api/#visturing.properties.prop1.download_data","title":"<code>download_data(data_path)</code>","text":"Source code in <code>visturing/properties/prop1.py</code> <pre><code>def download_data(data_path, # Path to download the data\n                  ):\n    # if not os.path.exists(data_path):\n    #     os.makedirs(data_path)\n    data_url = \"https://zenodo.org/records/17700252/files/Experiment_1.zip\"\n    path = wget.download(data_url)\n    with ZipFile(path) as zipObj:\n        zipObj.extractall(data_path)\n    os.remove(path)\n    return os.path.join(data_path, \"Experiment_1\")\n</code></pre>"},{"location":"api/#visturing.properties.prop1.evaluate","title":"<code>evaluate(calculate_diffs, data_path='Data/Experiment_1', gt_path='ground_truth_decalogo')</code>","text":"Source code in <code>visturing/properties/prop1.py</code> <pre><code>def evaluate(calculate_diffs,\n             data_path: str = \"Data/Experiment_1\",\n             gt_path: str = \"ground_truth_decalogo\",\n             ): # Tuple (lambdas, diffs, correlation)\n\n    if not os.path.exists(data_path):\n        data_path = download_data(\"/\".join(data_path.split(\"/\")[:-1]))\n\n    imgs, ref_img, lambdas = load_data(data_path)\n\n    diffs = calculate_diffs(imgs, ref_img[None,...])\n\n    x, a, _, _ = load_ground_truth(gt_path)\n    a_interp = np.interp(lambdas, x, a)\n    corr, p_value = pearsonr(diffs, a_interp)\n\n    return {\"lambdas\": lambdas,\n            \"diffs\": diffs,\n            \"correlations\":\n                {\"pearson\": corr},\n            \"p_values\":\n                {\"pearson\": p_value},\n            }\n</code></pre>"},{"location":"api/#visturing.properties.prop1.load_data","title":"<code>load_data(root_path)</code>","text":"Source code in <code>visturing/properties/prop1.py</code> <pre><code>def load_data(root_path: str,\n              ): # Tuple (imgs, reference_image)\n    ref_path = os.path.join(root_path, \"im_ref.png\")\n    lambdas = np.load(os.path.join(root_path, \"lambdas.npy\"))\n\n    imgs_path = [p for p in glob(os.path.join(root_path, \"*png\")) if \"ref\" not in p]\n    imgs_path = list(natsorted(imgs_path))\n\n    def load_img(path):\n        img = cv2.imread(path)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        return img\n\n    ref_img = load_img(ref_path)\n    imgs = np.array([load_img(p) for p in imgs_path])\n    lambdas = np.linspace(lambdas.min(), lambdas.max(), num=len(imgs))\n\n    return imgs, ref_img, lambdas\n</code></pre>"},{"location":"api/#visturing.properties.prop1.load_ground_truth","title":"<code>load_ground_truth(root_path='ground_truth_decalogo')</code>","text":"Source code in <code>visturing/properties/prop1.py</code> <pre><code>def load_ground_truth(root_path: str = \"ground_truth_decalogo\", # Path to the root containing all the ground truth files\n                      ): # Tuple (x, achromatic, red-green, yellow-blue)\n    data = sio.loadmat(os.path.join(root_path, \"spectral_sensitivities.mat\"))\n    data = data[\"spectral_sensitivities\"]\n\n    x = data[0]\n    a = data[1]\n    rg = data[2]\n    yb = data[3]\n\n    return (x, a, rg, yb)\n</code></pre>"},{"location":"api/#visturing.properties.prop1.plot_ground_truth","title":"<code>plot_ground_truth(x, a, rg, yb)</code>","text":"Source code in <code>visturing/properties/prop1.py</code> <pre><code>def plot_ground_truth(x,\n                      a,\n                      rg,\n                      yb,\n                      ): #\u00a0Returns both the fig and axes objects\n    fig, axes = plt.subplots(1,2, sharex=True, sharey=False, figsize=(10,4))\n    axes[0].plot(x, a, \"k\", label=\"Achromatic\")\n\n    axes[0].set_xlim([380, 720])\n    axes[0].set_ylim([0, 1.1])\n    axes[0].legend()\n\n    axes[1].plot(x, rg, \"r\", label=\"Red-Green\")\n    axes[1].plot(x, yb, \"b\", label=\"Yellow-Blue\")\n    axes[1].set_xlim([380, 720])\n    axes[1].set_ylim([-0.7, 0.7])\n\n    axes[1].legend()\n\n    axes[0].set_xlabel(r\"Wavelength ($\\lambda$)\")\n    axes[0].set_ylabel(\"Visibility\")\n    axes[1].set_xlabel(r\"Wavelength ($\\lambda$)\")\n\n    return fig, axes\n</code></pre>"},{"location":"api/#visturing.properties.prop10","title":"<code>prop10</code>","text":""},{"location":"api/#visturing.properties.prop10.download_data","title":"<code>download_data(data_path)</code>","text":"Source code in <code>visturing/properties/prop10.py</code> <pre><code>def download_data(data_path, # Path to download the data\n                  ):\n    # if not os.path.exists(data_path):\n    #     os.makedirs(data_path)\n    data_url = \"https://zenodo.org/records/17700252/files/Experiment_10.zip\"\n    path = wget.download(data_url)\n    with ZipFile(path) as zipObj:\n        zipObj.extractall(data_path)\n    os.remove(path)\n    return os.path.join(data_path, \"Experiment_10\")\n</code></pre>"},{"location":"api/#visturing.properties.prop10.evaluate","title":"<code>evaluate(calculate_diffs, data_path, gt_path)</code>","text":"Source code in <code>visturing/properties/prop10.py</code> <pre><code>def evaluate(calculate_diffs,\n             data_path,\n             gt_path,\n             ):\n\n    if not os.path.exists(data_path):\n        data_path = download_data(\"/\".join(data_path.split(\"/\")[:-1]))\n\n    xs = np.load(os.path.join(data_path, \"contrasts.npy\"))\n    data_high = {re.findall(\"high_(\\w+)\\.\", p)[0]: np.load(p) for p in glob(os.path.join(data_path, \"*\")) if \"high\" in p}\n    data_low = {re.findall(\"low_(\\w+)\\.\", p)[0]: np.load(p) for p in glob(os.path.join(data_path, \"*\")) if \"_low_\" in p}\n\n\n    f_mask = ['No mask', 'Theta_mask = 0', 'Theta_mask = 22.5', 'Theta_mask = 45', 'Theta_mask = 67.5', 'Theta_mask = 90', 'Theta_mask = 112.5', 'Theta_mask = 135']\n\n    diffs_high = defaultdict(dict)\n    for name, chroma in data_high.items():\n        for f, dat in zip(f_mask, chroma):\n            diffs_ = calculate_diffs(dat, dat[0:1])\n            diffs_high[name][f] = diffs_\n\n    diffs_low = defaultdict(dict)\n    for name, chroma in data_low.items():\n        for f, dat in zip(f_mask, chroma):\n            diffs_ = calculate_diffs(dat, dat[0:1])\n            diffs_low[name][f] = diffs_\n\n\n    diffs_low_s = np.array([a for a in diffs_low[\"achrom\"].values()])\n\n    order_corr = {}\n    order_corr[\"low\"] = calculate_spearman(diffs_low_s, ideal_ordering=[0,7,6,5,3,1,2,4])\n\n    diffs_high_s = np.array([a for a in diffs_high[\"achrom\"].values()])\n    order_corr[\"high\"] = calculate_spearman(diffs_high_s, ideal_ordering=[0,7,6,5,3,1,2,4])\n\n    return {\"correlations\":\n                {\"kendall\": order_corr},\n            \"p_values\":\n                {}\n            }\n</code></pre>"},{"location":"api/#visturing.properties.prop10.load_ground_truth","title":"<code>load_ground_truth(root_path='../../ground_truth_decalogo', return_freqs=False)</code>","text":"Source code in <code>visturing/properties/prop10.py</code> <pre><code>def load_ground_truth(root_path: str = \"../../ground_truth_decalogo\", # Path to the root containing all the ground truth files\n                      return_freqs: bool = False, # Return the frequencies corresponding to each response\n                      ): # Tuple (x, y1, y2, y3)\n    data = sio.loadmat(os.path.join(root_path, \"responses_no_mask_achrom_1p5_3_6_12_24.mat\"))\n    data = data[\"resp_no_mask_achrom\"]\n    x, y = data[0], data[1:]\n    y_low, y_high = y[1], y[-2]\n    freqs = [3, 12]\n\n    if return_freqs:\n        return x, y_low, y_high, freqs\n    else:\n        return x, y_low, y_high\n</code></pre>"},{"location":"api/#visturing.properties.prop10.plot_ground_truth","title":"<code>plot_ground_truth(x, y_low, y_high, freqs=(3, 12), figsize=(14, 4))</code>","text":"Source code in <code>visturing/properties/prop10.py</code> <pre><code>def plot_ground_truth(x,\n                      y_low,\n                      y_high,\n                      freqs=(3, 12),\n                      figsize=(14,4),\n                      ): #\u00a0Returns both the fig and axes objects\n\n    fig, axes = plt.subplots(1,2, sharex=True, sharey=True, figsize=(10,4))\n    axes[0].plot(x, y_low, color=\"b\", label=f\"{freqs[0]} cpd\")\n    axes[1].plot(x, y_high, color=\"b\", label=f\"{freqs[1]} cpd\")\n    for ax in axes.ravel():\n        ax.legend()\n        ax.set_xlabel(\"Contrast\")\n    axes[0].set_ylabel(\"Visibility\")\n    return fig, axes\n</code></pre>"},{"location":"api/#visturing.properties.prop2","title":"<code>prop2</code>","text":""},{"location":"api/#visturing.properties.prop2.download_data","title":"<code>download_data(data_path)</code>","text":"Source code in <code>visturing/properties/prop2.py</code> <pre><code>def download_data(data_path, # Path to download the data\n                  ):\n    # if not os.path.exists(data_path):\n    #     os.makedirs(data_path)\n    data_url = \"https://zenodo.org/records/17700252/files/Experiment_2.zip\"\n    path = wget.download(data_url)\n    with ZipFile(path) as zipObj:\n        zipObj.extractall(data_path)\n    os.remove(path)\n    return os.path.join(data_path, \"Experiment_2\")\n</code></pre>"},{"location":"api/#visturing.properties.prop2.evaluate","title":"<code>evaluate(calculate_diffs, data_path='Data/Experiment_2', gt_path='ground_truth_decalogo')</code>","text":"Source code in <code>visturing/properties/prop2.py</code> <pre><code>def evaluate(calculate_diffs,\n             data_path: str = \"Data/Experiment_2\",\n             gt_path: str = \"ground_truth_decalogo\",\n             ): # Tuple (responses, correlations)\n\n    if not os.path.exists(data_path):\n        data_path = download_data(\"/\".join(data_path.split(\"/\")[:-1]))\n\n    ##\u00a0Load ground truth\n    x_a_gt, y_a_gt, x_rg_gt, y_rg_gt, x_yb_gt, y_yb_gt = load_ground_truth(gt_path)\n\n    ## Load data\n    x_a, x_rg, x_yb = load_data(data_path)\n\n    data = {p.split(\"/\")[-1].split(\".\")[0]: np.load(p) for p in glob(os.path.join(data_path, \"*npy\")) if \"bgs\" not in p}\n    bgs = {p.split(\"/\")[-1].split(\".\")[0][4:]: np.load(p) for p in glob(os.path.join(data_path, \"*npy\")) if \"bgs\" in p}\n\n    diffs = {}\n    for c in [\"achrom\", \"red_green\", \"yellow_blue\"]:\n        diffs[c] = []\n        data_ = data[c]\n        bgs_ = bgs[c]\n        for cc, bg in zip(data_, bgs_):\n            diff = calculate_diffs(cc, bg[None,...])\n            diffs[c].append(diff)\n    diffs = {k: np.array(v) for k, v in diffs.items()}\n\n    ##\u00a0Calculate Order Correlation\n    spearman_correlations = {}\n\n    a, b, c, d = prepare_data(x_a, diffs[\"achrom\"], x_a_gt, y_a_gt)\n    spearman_correlations[\"achrom\"] = calculate_spearman(b, ideal_ordering=[0,1,2,3,4])\n\n    a, b_rg, c, d_rg = prepare_data(x_rg, diffs[\"red_green\"], x_rg_gt, y_rg_gt)\n    spearman_correlations[\"red_green\"] = calculate_spearman(b_rg, ideal_ordering=[0,1,2,3,4])\n\n    a, b_yb, c, d_yb = prepare_data(x_yb, diffs[\"yellow_blue\"], x_yb_gt, y_yb_gt)\n    spearman_correlations[\"yellow_blue\"] = calculate_spearman(b_yb, ideal_ordering=[0,1,2,3,4])\n\n    # Calculate Pearson\n    ## Achromatic\n\n    corr_achrom, p_value_achrom = pearsonr(\n        np.concatenate([\n            b[0].ravel(),\n        ]),\n        np.concatenate([\n            d.ravel(),\n        ])\n    )\n    ## Both Chromatics Together\n    corr_chroma, p_value_chroma = pearsonr(\n        np.concatenate([\n            b_rg[2].ravel(), b_yb[2].ravel(),\n        ]),\n        np.concatenate([\n            d_rg.ravel(), d_yb.ravel(),\n        ])\n    )\n    correlations = {\"pearson_achrom\": corr_achrom, \"pearson_chrom\": corr_chroma, \"kendall\": spearman_correlations}\n\n    return {\"diffs\": diffs,\n            \"correlations\": correlations,\n            \"p_values\":\n                {\"achrom\": p_value_achrom,\n                 \"red_green\": p_value_chroma},\n            }\n</code></pre>"},{"location":"api/#visturing.properties.prop2.load_data","title":"<code>load_data(data_path)</code>","text":"Source code in <code>visturing/properties/prop2.py</code> <pre><code>def load_data(data_path):\n    x_a = np.load(os.path.join(data_path, \"luminancias.npy\"))\n    x_rg = np.load(os.path.join(data_path, \"x_rg.npy\"))\n    x_yb = np.load(os.path.join(data_path, \"x_yb.npy\"))\n    return x_a, x_rg, x_yb\n</code></pre>"},{"location":"api/#visturing.properties.prop2.load_ground_truth","title":"<code>load_ground_truth(data_path='ground_truth_decalogo')</code>","text":"Source code in <code>visturing/properties/prop2.py</code> <pre><code>def load_ground_truth(data_path: str = \"ground_truth_decalogo\", # Path to the root containing all the ground truth files\n                      ): # Tuple of tuples (x, y), (x_c, red-green), (x_c, yellow-blue)\n    data = sio.loadmat(os.path.join(data_path, \"weber.mat\"))\n    data = data[\"weber\"]\n\n    x = data[0]\n    y = data[1]\n\n    data = sio.loadmat(os.path.join(data_path, \"resp_RG.mat\"))\n    data = data[\"resp_RG\"]\n    x_c, rg, _ = data\n\n    data = sio.loadmat(os.path.join(data_path, \"resp_YB.mat\"))\n    data = data[\"resp_YB\"]\n    _, yb = data\n\n    return x, y, x_c, rg, x_c, yb\n</code></pre>"},{"location":"api/#visturing.properties.prop2.load_images","title":"<code>load_images(data_path)</code>","text":"Source code in <code>visturing/properties/prop2.py</code> <pre><code>def load_images(data_path):\n    data = {p.split(\"/\")[-1].split(\".\")[0]: np.load(p, allow_pickle=True) for p in glob(os.path.join(data_path, \"*npy\")) if \"bgs\" not in p and \"luminancias\" not in p and \"x_rg\" not in p and \"x_yb\" not in p}\n    bgs = {p.split(\"/\")[-1].split(\".\")[0][4:]: np.load(p, allow_pickle=True) for p in glob(os.path.join(data_path, \"*npy\")) if \"bgs\" in p}\n    return data, bgs\n</code></pre>"},{"location":"api/#visturing.properties.prop2.plot_ground_truth","title":"<code>plot_ground_truth(x, y, x_c, rg, x_cc, yb)</code>","text":"Source code in <code>visturing/properties/prop2.py</code> <pre><code>def plot_ground_truth(x,y,\n                      x_c, rg,\n                      x_cc, yb,\n                      ): #\u00a0Returns both the fig and axes objects\n    fig, axes = plt.subplots(1,3, figsize=(18,5))\n    axes[0].plot(x, y, \"b\")\n    axes[1].plot(x_c, rg, \"gray\")\n    axes[2].plot(x_c, yb, \"gray\")\n    for ax, name in zip(axes, [\"Achromatic\", \"Red-Green\", \"Yellow-Blue\"]): ax.set_title(name)\n    axes[0].set_xlabel(r\"Luminance (cd/m$^2$)\")\n    axes[1].set_xlabel(\"Linear RG\")\n    axes[2].set_xlabel(\"Linear YB\")\n    for ax, name in zip(axes, [\"Brightness\", \"Nonlinear RG\", \"Nonlinear YB\"]): ax.set_ylabel(name)\n    axes[1].set_xlim([-22,22])\n    axes[1].set_ylim([-8,8])\n    axes[2].set_xlim([-22,22])\n    axes[2].set_ylim([-8,8])\n    return fig, axes\n</code></pre>"},{"location":"api/#visturing.properties.prop3_4","title":"<code>prop3_4</code>","text":""},{"location":"api/#visturing.properties.prop3_4.download_data","title":"<code>download_data(data_path)</code>","text":"Source code in <code>visturing/properties/prop3_4.py</code> <pre><code>def download_data(data_path, # Path to download the data\n                  ):\n    # if not os.path.exists(data_path):\n    #     os.makedirs(data_path)\n    data_url = \"https://zenodo.org/records/17700252/files/Experiment_3_4.zip\"\n    path = wget.download(data_url)\n    with ZipFile(path) as zipObj:\n        zipObj.extractall(data_path)\n    os.remove(path)\n    return os.path.join(data_path, \"Experiment_3_4\")\n</code></pre>"},{"location":"api/#visturing.properties.prop3_4.evaluate","title":"<code>evaluate(calculate_diffs, data_path, gt_path)</code>","text":"Source code in <code>visturing/properties/prop3_4.py</code> <pre><code>def evaluate(calculate_diffs,\n             data_path,\n             gt_path,\n             ):\n\n    if not os.path.exists(data_path):\n        data_path = download_data(\"/\".join(data_path.split(\"/\")[:-1]))\n\n    ## Load ground truth\n    x_gt, y_gt, rg_gt, yb_gt = load_ground_truth(gt_path)\n\n    ## Load data\n    noises = {p.split(\"/\")[-1].split(\".\")[0].split(\"_\")[-1]:np.load(p) for p in glob(os.path.join(data_path, \"*\")) if \"noises\" in p}\n    bg = np.load(os.path.join(data_path, \"background.npy\"))\n\n    ## Calculate the differences\n    diffs = {}\n    for k, noises_ in noises.items():\n        diffs_it = []\n        for noise_it in noises_:\n            diff = calculate_diffs(noise_it, bg[None,...])\n            # print(noise_it.shape, bg.shape, diff.shape)\n            diffs_it.append(diff)\n            # break\n        diffs_it = np.array(diffs_it)\n        diffs[k] = diffs_it.mean(axis=0)\n\n    gt_s = np.stack([y_gt,\n                    rg_gt,\n                    yb_gt])\n\n\n    diffs_s = np.stack([diffs[\"a\"],\n                        diffs[\"rg\"],\n                        diffs[\"yb\"]])\n\n    freqs = load_data(data_path)\n\n    bs, ds = [], []\n    for d, gt in zip(diffs_s, gt_s):\n        a, b, c, d = prepare_data(freqs, d, x_gt, gt)\n        bs.append(b)\n        ds.append(d)\n    b = np.array(bs)\n    d = np.array(ds)\n\n    order_corr = calculate_correlations_with_ground_truth(b, d)\n    pearson_corr, p_value_pearson = pearsonr(b.ravel(), d.ravel())\n\n    return {\"diffs_s\": diffs_s,\n            \"correlations\":\n                {\"pearson\": pearson_corr, \"kendall\": order_corr},\n            \"p_values\": \n                {\"pearson\": p_value_pearson},\n        }\n</code></pre>"},{"location":"api/#visturing.properties.prop3_4.load_data","title":"<code>load_data(root_path)</code>","text":"Source code in <code>visturing/properties/prop3_4.py</code> <pre><code>def load_data(root_path: str):\n    freqs = np.load(os.path.join(root_path, \"freq.npy\"))\n    return freqs\n</code></pre>"},{"location":"api/#visturing.properties.prop3_4.load_ground_truth","title":"<code>load_ground_truth(root_path='../../ground_truth_decalogo')</code>","text":"Source code in <code>visturing/properties/prop3_4.py</code> <pre><code>def load_ground_truth(root_path: str = \"../../ground_truth_decalogo\", # Path to the root containing all the ground truth files\n                      ): # Tuple (x, y, red-green, yellow-blue)\n    data = sio.loadmat(os.path.join(root_path, \"responses_CSF_achrom.mat\"))\n    data = data[\"CSF_achrom\"]\n    x, y = data\n    data = sio.loadmat(os.path.join(root_path, \"responses_CSF_RG.mat\"))\n    data = data[\"CSF_RG\"]\n    _, rg = data\n    data = sio.loadmat(os.path.join(root_path, \"responses_CSF_YB.mat\"))\n    data = data[\"CSF_YB\"]\n    _, yb = data\n    return x, y, rg, yb\n</code></pre>"},{"location":"api/#visturing.properties.prop3_4.plot_ground_truth","title":"<code>plot_ground_truth(x, y, rg, yb)</code>","text":"Source code in <code>visturing/properties/prop3_4.py</code> <pre><code>def plot_ground_truth(x,\n                      y,\n                      rg,\n                      yb,\n                      ): #\u00a0Returns both the fig and axes objects\n    fig, axes = plt.subplots()\n    axes.plot(x, y, \"k\", label=\"Achromatic\")\n    axes.plot(x, rg, \"r\", label=\"Red-Green\")\n    axes.plot(x, yb, \"b\", label=\"Yellow-Blue\")\n    axes.set_xscale(\"log\")\n    axes.set_yscale(\"log\")\n    axes.set_xlim([1,32])\n    axes.set_ylim(bottom=0.3)\n    axes.legend()\n    axes.set_xlabel(\"Frequency (cpd)\")\n    axes.set_ylabel(\"Sensitivity\")\n    return fig, axes\n</code></pre>"},{"location":"api/#visturing.properties.prop5","title":"<code>prop5</code>","text":""},{"location":"api/#visturing.properties.prop5.download_data","title":"<code>download_data(data_path)</code>","text":"Source code in <code>visturing/properties/prop5.py</code> <pre><code>def download_data(data_path, # Path to download the data\n                  ):\n    # if not os.path.exists(data_path):\n    #     os.makedirs(data_path)\n    data_url = \"https://zenodo.org/records/17700252/files/Experiment_5.zip\"\n    path = wget.download(data_url)\n    with ZipFile(path) as zipObj:\n        zipObj.extractall(data_path)\n    os.remove(path)\n    return os.path.join(data_path, \"Experiment_5\")\n</code></pre>"},{"location":"api/#visturing.properties.prop5.evaluate","title":"<code>evaluate(calculate_diffs, data_path, gt_path)</code>","text":"Source code in <code>visturing/properties/prop5.py</code> <pre><code>def evaluate(calculate_diffs,\n             data_path,\n             gt_path,\n             ):\n\n    if not os.path.exists(data_path):\n        data_path = download_data(\"/\".join(data_path.split(\"/\")[:-1]))\n\n    x_gt, y1_gt, y2_gt, y3_gt = load_ground_truth(gt_path)\n\n    noises = {p.split(\"/\")[-1].split(\".\")[0].split(\"_\")[-1]: np.load(p) for p in glob(os.path.join(data_path, \"*npy\")) if \"noises\" in p}\n    bgs = {p.split(\"/\")[-1].split(\".\")[0].split(\"_\")[-1]: np.load(p) for p in glob(os.path.join(data_path, \"*npy\")) if \"background\" in p}\n    freqs = np.load(os.path.join(data_path, \"freqs.npy\"))\n\n\n    diffs = {}\n    for k, noise in noises.items():\n        bg = bgs[k][None,...]\n        diffs_it = []\n        for noise_it in noise:\n            diff = calculate_diffs(noise_it, bg)\n            # print(noise_it.shape, bg.shape, diff.shape)\n            diffs_it.append(diff)\n            # break\n        diffs_it = np.array(diffs_it)\n        diffs[k] = diffs_it.mean(axis=0)\n        # break\n\n\n    diffs_a = diffs.pop(\"a\")\n    diffs_inv = {k:(diffs_a+1e-6)/v for k, v in diffs.items()}\n    diffs_inv = {k:(v-1) for k, v in diffs_inv.items()}\n    diffs_inv = {k:np.clip(v, a_min=1e-6, a_max=np.inf) for k, v in diffs_inv.items()}\n    diffs_inv = {k:v/v.max() for k, v in diffs_inv.items()}\n\n    k = list(diffs_inv.keys())[0]\n    a, b, c, d1 = prepare_data(freqs[1:], diffs_inv[k][1:], x_gt, y1_gt)\n    a, b, c, d2 = prepare_data(freqs[1:], diffs_inv[k][1:], x_gt, y2_gt)\n    a, b, c, d3 = prepare_data(freqs[1:], diffs_inv[k][1:], x_gt, y3_gt)\n\n\n    diffs_stack = np.stack([diffs_inv[\"3\"][1:],\n                            diffs_inv[\"6\"][1:],\n                            diffs_inv[\"12\"][1:]])\n    ds = np.stack([d1, d2, d3])\n\n    order_corr = calculate_correlations_with_ground_truth(diffs_stack, ds)\n    pearson_corr, p_value_pearson = pearsonr(diffs_stack.ravel(), ds.ravel())\n\n    return {\"ds\": ds,\n            \"diffs\": diffs_stack,\n            \"correlations\":\n                {\"pearson\": pearson_corr, \"kendall\": order_corr},\n            \"p_values\":\n                {\"pearson\": p_value_pearson},\n        }\n</code></pre>"},{"location":"api/#visturing.properties.prop5.load_ground_truth","title":"<code>load_ground_truth(root_path='../../ground_truth_decalogo')</code>","text":"Source code in <code>visturing/properties/prop5.py</code> <pre><code>def load_ground_truth(root_path: str = \"../../ground_truth_decalogo\", # Path to the root containing all the ground truth files\n                      ): # Tuple (x, y1, y2, y3)\n    data = sio.loadmat(os.path.join(root_path, \"Campbell_Blakemore.mat\"))\n    data = data[\"Campbell_Blakemore\"]\n    x, y1, y2, y3 = data\n    return x, y1, y2, y3\n</code></pre>"},{"location":"api/#visturing.properties.prop5.plot_ground_truth","title":"<code>plot_ground_truth(x, y1, y2, y3)</code>","text":"Source code in <code>visturing/properties/prop5.py</code> <pre><code>def plot_ground_truth(x,\n                      y1,\n                      y2,\n                      y3,\n                      ): #\u00a0Returns both the fig and axes objects\n    fig, axes = plt.subplots()\n    axes.plot(x, y1, \"k\", linestyle=\"-\", label=\"3 cpd\")\n    axes.plot(x, y2, \"k\", linestyle=\":\", label=\"6 cpd\")\n    axes.plot(x, y3, \"k\", linestyle=\"-.\", label=\"12 cpd\")\n    axes.set_xlabel(\"Frequency (cpd)\")\n    axes.set_xscale(\"log\")\n    axes.set_xlim([1,32])\n    axes.legend()\n    return fig, axes\n</code></pre>"},{"location":"api/#visturing.properties.prop6_7","title":"<code>prop6_7</code>","text":""},{"location":"api/#visturing.properties.prop6_7.download_data","title":"<code>download_data(data_path)</code>","text":"Source code in <code>visturing/properties/prop6_7.py</code> <pre><code>def download_data(data_path, # Path to download the data\n                  ):\n    # if not os.path.exists(data_path):\n    #     os.makedirs(data_path)\n    data_url = \"https://zenodo.org/records/17700252/files/Experiment_6_7.zip\"\n    path = wget.download(data_url)\n    with ZipFile(path) as zipObj:\n        zipObj.extractall(data_path)\n    os.remove(path)\n    return os.path.join(data_path, \"Experiment_6_7\")\n</code></pre>"},{"location":"api/#visturing.properties.prop6_7.evaluate","title":"<code>evaluate(calculate_diffs, data_path, gt_path)</code>","text":"Source code in <code>visturing/properties/prop6_7.py</code> <pre><code>def evaluate(calculate_diffs,\n             data_path,\n             gt_path,\n             ):\n\n    if not os.path.exists(data_path):\n        data_path = download_data(\"/\".join(data_path.split(\"/\")[:-1]))\n\n    x_gt, y_gt, rg_gt, yb_gt = load_ground_truth(gt_path)\n    data = {re.findall(\"noise_(\\w+)\\.\", p)[0]: np.load(p) for p in glob(os.path.join(data_path, \"*\")) if \"gabor\" in p}\n    freqs = np.array([1.5, 3, 6, 12, 24])\n\n    diffs = defaultdict(dict)\n    for name, chroma in data.items():\n        for f, dat in zip(freqs, chroma):\n            diffs_ = calculate_diffs(dat, dat[0:1])\n            diffs[name][f] = diffs_\n\n    x_a, x_rg, x_yb = load_data(data_path)\n\n    diffs_a = np.array([a for a in diffs[\"achrom\"].values()])\n    diffs_rg = np.array([a for a in diffs[\"red_green\"].values()])\n    diffs_yb = np.array([a for a in diffs[\"yellow_blue\"].values()])\n\n    bs, ds = [], []\n    for b, d in zip(diffs_a, y_gt):\n        a, b, c, d = prepare_data(x_a, b, x_gt, d)\n        bs.append(b)\n        ds.append(d)\n    b_a = np.array(bs)\n    d_a = np.array(ds)\n\n    order_corr = {}\n    order_corr[\"achrom\"] = calculate_correlations_with_ground_truth(b_a, d_a)\n\n    bs, ds = [], []\n    for b, d in zip(diffs_rg, rg_gt):\n        a, b, c, d = prepare_data(x_rg, b, x_gt, d)\n        bs.append(b)\n        ds.append(d)\n    b_rg = np.array(bs)\n    d_rg = np.array(ds)\n\n\n    order_corr[\"red_green\"] = calculate_correlations_with_ground_truth(b_rg, d_rg)\n\n\n    bs, ds = [], []\n    for b, d in zip(diffs_yb, yb_gt):\n        a, b, c, d = prepare_data(x_yb, b, x_gt, d)\n        bs.append(b)\n        ds.append(d)\n    b_yb = np.array(bs)\n    d_yb = np.array(ds)\n\n\n    order_corr[\"yellow_blue\"] = calculate_correlations_with_ground_truth(b_yb, d_yb)\n\n\n    b_cat = np.concatenate([\n            b_a.ravel(), b_rg.ravel(), b_yb.ravel(),\n        ])\n    nan_mask = np.isnan(b_cat)\n    d_cat = np.concatenate([\n            d_a.ravel(), d_rg.ravel(), d_yb.ravel(),\n        ])\n    pearson, p_value_pearson = pearsonr(\n        b_cat[~nan_mask], d_cat[~nan_mask]\n    )\n\n    return {\"diffs\": diffs,\n            \"correlations\":\n                {\"kendall\": order_corr, \"pearson\": pearson},\n            \"p_values\":\n                {\"pearson\": p_value_pearson}\n            }\n</code></pre>"},{"location":"api/#visturing.properties.prop6_7.load_data","title":"<code>load_data(root_path)</code>","text":"Source code in <code>visturing/properties/prop6_7.py</code> <pre><code>def load_data(root_path):\n    c_a = np.load(os.path.join(root_path, \"contrast_a.npy\"))\n    c_rg = np.load(os.path.join(root_path, \"contrast_rg.npy\"))\n    c_yb = np.load(os.path.join(root_path, \"contrast_yb.npy\"))\n    return c_a, c_rg, c_yb\n</code></pre>"},{"location":"api/#visturing.properties.prop6_7.load_ground_truth","title":"<code>load_ground_truth(root_path='../../ground_truth_decalogo')</code>","text":"Source code in <code>visturing/properties/prop6_7.py</code> <pre><code>def load_ground_truth(root_path: str = \"../../ground_truth_decalogo\", # Path to the root containing all the ground truth files\n                      ): # Tuple (x, y, y_rg, y_yb)\n    data = sio.loadmat(os.path.join(root_path, \"responses_no_mask_achrom_1p5_3_6_12_24.mat\"))\n    data = data[\"resp_no_mask_achrom\"]\n    x, y = data[0], data[1:]\n\n    data = sio.loadmat(os.path.join(root_path, \"responses_no_mask_RG_1p5_3_6_12_24.mat\"))\n    data = data[\"resp_no_mask_RG\"]\n    x, y_rg = data[0], data[1:]\n\n    data = sio.loadmat(os.path.join(root_path, \"responses_no_mask_YB_1p5_3_6_12_24.mat\"))\n    data = data[\"resp_no_mask_YB\"]\n    x, y_yb = data[0], data[1:]\n\n    return x, y, y_rg, y_yb\n</code></pre>"},{"location":"api/#visturing.properties.prop6_7.plot_ground_truth","title":"<code>plot_ground_truth(x, y, y_rg, y_yb, figsize=(14, 4))</code>","text":"Source code in <code>visturing/properties/prop6_7.py</code> <pre><code>def plot_ground_truth(x,\n                      y,\n                      y_rg,\n                      y_yb,\n                      figsize=(14,4),\n                      ): #\u00a0Returns both the fig and axes objects\n    freqs = [1.5, 3, 6, 12, 24]\n    colors = [\"lightgray\", \"black\", \"blue\", \"gray\", \"red\"]\n    colors_rg = [\"blue\", \"black\", \"gray\", \"lightgray\", \"red\"]\n    colors_yb = [\"blue\", \"black\", \"gray\", \"lightgray\", \"red\"]\n\n    fig, axes = plt.subplots(1,3, figsize=figsize, sharex=True, sharey=True)\n    for y_, f, c in zip(y, freqs, colors):\n        axes[0].plot(x, y_, color=c, label=f\"Freq {f}\")\n    for y_, f, c in zip(y_rg, freqs, colors_rg):\n        axes[1].plot(x, y_, color=c, label=f\"Freq {f}\")\n    for y_, f, c in zip(y_yb, freqs, colors_yb):\n        axes[2].plot(x, y_, color=c, label=f\"Freq {f}\")\n    axes[0].set_ylabel(\"Visibility\")\n    for ax in axes.ravel():\n        ax.set_xlabel(\"Contrast\")\n        ax.legend()\n    return fig, axes\n</code></pre>"},{"location":"api/#visturing.properties.prop8","title":"<code>prop8</code>","text":""},{"location":"api/#visturing.properties.prop8.download_data","title":"<code>download_data(data_path)</code>","text":"Source code in <code>visturing/properties/prop8.py</code> <pre><code>def download_data(data_path, # Path to download the data\n                  ):\n    # if not os.path.exists(data_path):\n    #     os.makedirs(data_path)\n    data_url = \"https://zenodo.org/records/17700252/files/Experiment_8.zip\"\n    path = wget.download(data_url)\n    with ZipFile(path) as zipObj:\n        zipObj.extractall(data_path)\n    os.remove(path)\n    return os.path.join(data_path, \"Experiment_8\")\n</code></pre>"},{"location":"api/#visturing.properties.prop8.evaluate","title":"<code>evaluate(calculate_diffs, data_path, gt_path)</code>","text":"Source code in <code>visturing/properties/prop8.py</code> <pre><code>def evaluate(calculate_diffs,\n             data_path,\n             gt_path,\n             ):\n\n    if not os.path.exists(data_path):\n        data_path = download_data(\"/\".join(data_path.split(\"/\")[:-1]))\n\n    xs = np.load(os.path.join(data_path, \"contrasts.npy\"))\n    data_high = {re.findall(\"high_(\\w+)\\.\", p)[0]: np.load(p) for p in glob(os.path.join(data_path, \"*\")) if \"high\" in p}\n    data_low = {re.findall(\"low_(\\w+)\\.\", p)[0]: np.load(p) for p in glob(os.path.join(data_path, \"*\")) if \"_low_\" in p}\n\n\n    c_mask = ['No mask', 'C_mask = 0.075', 'C_mask = 0.150', 'C_mask = 0.225', 'C_mask = 0.300']\n\n    diffs_high = defaultdict(dict)\n    for name, chroma in data_high.items():\n        for f, dat in zip(c_mask, chroma):\n            diffs_ = calculate_diffs(dat, dat[0:1])\n            diffs_high[name][f] = diffs_\n\n    diffs_low = defaultdict(dict)\n    for name, chroma in data_low.items():\n        for f, dat in zip(c_mask, chroma):\n            diffs_ = calculate_diffs(dat, dat[0:1])\n            diffs_low[name][f] = diffs_\n\n\n    x_gt, y_low_gt, y_high_gt  = load_ground_truth(gt_path)\n\n\n    diffs_low_a_s = np.array([a for a in diffs_low[\"achrom\"].values()])\n    diffs_low_rg_s = np.array([a for a in diffs_low[\"red_green\"].values()])\n    diffs_low_yb_s = np.array([a for a in diffs_low[\"yellow_blue\"].values()])\n\n\n    bs = []\n    for b in diffs_low_a_s:\n        a, b, c, d = prepare_data(xs, b, x_gt, y_low_gt)\n        bs.append(b)\n    b_low = np.array(bs)\n\n    order_corr = {}\n    order_corr[\"low\"] = calculate_spearman(b_low, ideal_ordering=[0,1,2,3,4])\n\n\n    diffs_high_a_s = np.array([a for a in diffs_high[\"achrom\"].values()])\n\n    bs = []\n    for b in diffs_high_a_s:\n        a, b, c, d = prepare_data(xs, b, x_gt, y_high_gt)\n        bs.append(b)\n    b_high = np.array(bs)\n\n    order_corr[\"high\"] = calculate_spearman(b_high, ideal_ordering=[0,1,2,3,4])\n\n    pearson, p_value_pearson = pearsonr(\n        np.concatenate([\n            b_low[0], b_high[0]\n        ]),\n        np.concatenate([\n            y_low_gt, y_high_gt\n        ])\n    )\n\n    return {\"diffs\":\n                {\"low\": diffs_low, \"high\": diffs_high},\n            \"correlations\":\n                {\"kendall\": order_corr, \"pearson\": pearson},\n            \"p_values\":\n                {\"pearson\": p_value_pearson}\n            }\n</code></pre>"},{"location":"api/#visturing.properties.prop8.load_ground_truth","title":"<code>load_ground_truth(root_path='../../ground_truth_decalogo', return_freqs=False)</code>","text":"Source code in <code>visturing/properties/prop8.py</code> <pre><code>def load_ground_truth(root_path: str = \"../../ground_truth_decalogo\", # Path to the root containing all the ground truth files\n                      return_freqs: bool = False, # Return the frequencies corresponding to each response\n                      ): # Tuple (x, y1, y2, y3)\n    data = sio.loadmat(os.path.join(root_path, \"responses_no_mask_achrom_1p5_3_6_12_24.mat\"))\n    data = data[\"resp_no_mask_achrom\"]\n    x, y = data[0], data[1:]\n    y_low, y_high = y[1], y[-2]\n    freqs = [3, 12]\n\n    if return_freqs:\n        return x, y_low, y_high, freqs\n    else:\n        return x, y_low, y_high\n</code></pre>"},{"location":"api/#visturing.properties.prop8.plot_ground_truth","title":"<code>plot_ground_truth(x, y_low, y_high, freqs=(3, 12), figsize=(14, 4))</code>","text":"Source code in <code>visturing/properties/prop8.py</code> <pre><code>def plot_ground_truth(x,\n                      y_low,\n                      y_high,\n                      freqs=(3, 12),\n                      figsize=(14,4),\n                      ): #\u00a0Returns both the fig and axes objects\n\n    fig, axes = plt.subplots(1,2, sharex=True, sharey=True, figsize=(10,4))\n    axes[0].plot(x, y_low, color=\"b\", label=f\"{freqs[0]} cpd\")\n    axes[1].plot(x, y_high, color=\"b\", label=f\"{freqs[1]} cpd\")\n    for ax in axes.ravel():\n        ax.legend()\n        ax.set_xlabel(\"Contrast\")\n    axes[0].set_ylabel(\"Visibility\")\n    return fig, axes\n</code></pre>"},{"location":"api/#visturing.properties.prop9","title":"<code>prop9</code>","text":""},{"location":"api/#visturing.properties.prop9.download_data","title":"<code>download_data(data_path)</code>","text":"Source code in <code>visturing/properties/prop9.py</code> <pre><code>def download_data(data_path, # Path to download the data\n                  ):\n    # if not os.path.exists(data_path):\n    #     os.makedirs(data_path)\n    data_url = \"https://zenodo.org/records/17700252/files/Experiment_9.zip\"\n    path = wget.download(data_url)\n    with ZipFile(path) as zipObj:\n        zipObj.extractall(data_path)\n    os.remove(path)\n    return os.path.join(data_path, \"Experiment_9\")\n</code></pre>"},{"location":"api/#visturing.properties.prop9.evaluate","title":"<code>evaluate(calculate_diffs, data_path, gt_path)</code>","text":"Source code in <code>visturing/properties/prop9.py</code> <pre><code>def evaluate(calculate_diffs,\n             data_path,\n             gt_path,\n             ):\n\n    if not os.path.exists(data_path):\n        data_path = download_data(\"/\".join(data_path.split(\"/\")[:-1]))\n\n    xs = np.load(os.path.join(data_path, \"contrasts.npy\"))\n    data_high = {re.findall(\"high_(\\w+)\\.\", p)[0]: np.load(p) for p in glob(os.path.join(data_path, \"*\")) if \"high\" in p}\n    data_low = {re.findall(\"low_(\\w+)\\.\", p)[0]: np.load(p) for p in glob(os.path.join(data_path, \"*\")) if \"_low_\" in p}\n\n\n    f_mask = ['No mask', 'F_mask = 1.5 cpd', 'F_mask = 3 cpd', 'F_mask = 6 cpd', 'F_mask = 12 cpd', 'F_mask = 24 cpd']\n\n    diffs_high = defaultdict(dict)\n    for name, chroma in data_high.items():\n        for f, dat in zip(f_mask, chroma):\n            diffs_ = calculate_diffs(dat, dat[0:1])\n            diffs_high[name][f] = diffs_\n\n    diffs_low = defaultdict(dict)\n    for name, chroma in data_low.items():\n        for f, dat in zip(f_mask, chroma):\n            diffs_ = calculate_diffs(dat, dat[0:1])\n            diffs_low[name][f] = diffs_\n\n\n    diffs_low_s = np.array([a for a in diffs_low[\"achrom\"].values()])\n\n    order_corr = {}\n    order_corr[\"low\"] = calculate_spearman(diffs_low_s, ideal_ordering=[0,4,5,3,2,1])\n\n    diffs_high_s = np.array([a for a in diffs_high[\"achrom\"].values()])\n\n    order_corr[\"high\"] = calculate_spearman(diffs_high_s, ideal_ordering=[0,1,2,3,5,4])\n    return {\"correlations\":\n                {\"kendall\": order_corr},\n            \"p_values\":\n                {}\n            }\n</code></pre>"},{"location":"api/#visturing.properties.prop9.load_ground_truth","title":"<code>load_ground_truth(root_path='../../ground_truth_decalogo', return_freqs=False)</code>","text":"Source code in <code>visturing/properties/prop9.py</code> <pre><code>def load_ground_truth(root_path: str = \"../../ground_truth_decalogo\", # Path to the root containing all the ground truth files\n                      return_freqs: bool = False, # Return the frequencies corresponding to each response\n                      ): # Tuple (x, y1, y2, y3)\n    data = sio.loadmat(os.path.join(root_path, \"responses_no_mask_achrom_1p5_3_6_12_24.mat\"))\n    data = data[\"resp_no_mask_achrom\"]\n    x, y = data[0], data[1:]\n    y_low, y_high = y[1], y[-2]\n    freqs = [3, 12]\n\n    if return_freqs:\n        return x, y_low, y_high, freqs\n    else:\n        return x, y_low, y_high\n</code></pre>"},{"location":"api/#visturing.properties.prop9.plot_ground_truth","title":"<code>plot_ground_truth(x, y_low, y_high, freqs=(3, 12), figsize=(14, 4))</code>","text":"Source code in <code>visturing/properties/prop9.py</code> <pre><code>def plot_ground_truth(x,\n                      y_low,\n                      y_high,\n                      freqs=(3, 12),\n                      figsize=(14,4),\n                      ): #\u00a0Returns both the fig and axes objects\n\n    fig, axes = plt.subplots(1,2, sharex=True, sharey=True, figsize=(10,4))\n    axes[0].plot(x, y_low, color=\"b\", label=f\"{freqs[0]} cpd\")\n    axes[1].plot(x, y_high, color=\"b\", label=f\"{freqs[1]} cpd\")\n    for ax in axes.ravel():\n        ax.legend()\n        ax.set_xlabel(\"Contrast\")\n    axes[0].set_ylabel(\"Visibility\")\n    return fig, axes\n</code></pre>"},{"location":"api/#visturing.properties.utils","title":"<code>utils</code>","text":""},{"location":"api/#visturing.properties.utils.download_ground_truth","title":"<code>download_ground_truth(data_path)</code>","text":"Source code in <code>visturing/properties/utils.py</code> <pre><code>def download_ground_truth(data_path, # Path to download the data\n                  ):\n    data_url = \"https://zenodo.org/records/17700252/files/ground_truth.zip\"\n    path = wget.download(data_url)\n    with ZipFile(path) as zipObj:\n        zipObj.extractall(data_path)\n    os.remove(path)\n    return os.path.join(data_path, \"ground_truth\")\n</code></pre>"},{"location":"api/#visturing.properties.utils.evaluate_all","title":"<code>evaluate_all(calculate_diffs, data_path, gt_path)</code>","text":"Source code in <code>visturing/properties/utils.py</code> <pre><code>def evaluate_all(calculate_diffs,\n                 data_path, # Path to the root directory\n                 gt_path, #\u00a0Path to the ground truth\n                 ):\n\n    if not os.path.exists(os.path.join(gt_path, \"ground_truth\")):\n        gt_path = download_ground_truth(gt_path)\n    else:\n        gt_path = os.path.join(gt_path, \"ground_truth\")\n\n    results = {}\n    results[\"prop1\"] = prop1.evaluate(calculate_diffs, os.path.join(data_path, \"Experiment_1\"), gt_path)\n    print('prop1 done')\n    results[\"prop2\"] = prop2.evaluate(calculate_diffs, os.path.join(data_path, \"Experiment_2\"), gt_path)\n    print('prop2 done')\n    results[\"prop3_4\"] = prop3_4.evaluate(calculate_diffs, os.path.join(data_path, \"Experiment_3_4\"), gt_path)\n    print('prop3_4 done')\n    results[\"prop5\"] = prop5.evaluate(calculate_diffs, os.path.join(data_path, \"Experiment_5\"), gt_path)\n    print('prop5 done')\n    results[\"prop6_7\"] = prop6_7.evaluate(calculate_diffs, os.path.join(data_path, \"Experiment_6_7\"), gt_path)\n    print('prop6_7 done')\n    results[\"prop8\"] = prop8.evaluate(calculate_diffs, os.path.join(data_path, \"Experiment_8\"), gt_path)\n    print('prop8 done')\n    results[\"prop9\"] = prop9.evaluate(calculate_diffs, os.path.join(data_path, \"Experiment_9\"), gt_path)\n    print('prop9 done')\n    results[\"prop10\"] = prop10.evaluate(calculate_diffs, os.path.join(data_path, \"Experiment_10\"), gt_path)\n    print('prop10 done')\n\n    return results\n</code></pre>"},{"location":"api/#visturing.ranking","title":"<code>ranking</code>","text":""},{"location":"api/#visturing.ranking.calculate_correlations","title":"<code>calculate_correlations(ground_truth, experimental)</code>","text":"Source code in <code>visturing/ranking.py</code> <pre><code>def calculate_correlations(ground_truth, experimental):\n    return {\n        \"spearman\": stats.spearmanr(ground_truth.ravel(),\n                                    experimental.ravel())[0],\n        \"kendall\": stats.kendalltau(ground_truth.ravel(),\n                                    experimental.ravel())[0],\n        \"pearson\": stats.pearsonr(ground_truth.ravel(),\n                                    experimental.ravel())[0],\n    }\n</code></pre>"},{"location":"api/#visturing.ranking.calculate_correlations_with_ground_truth","title":"<code>calculate_correlations_with_ground_truth(experimental_curve, ground_truth)</code>","text":"Source code in <code>visturing/ranking.py</code> <pre><code>def calculate_correlations_with_ground_truth(experimental_curve, ground_truth):\n    gt_ordering = (-ground_truth).argsort(axis=0)\n    e_ordering = (-experimental_curve).argsort(axis=0)\n    return calculate_correlations(gt_ordering.ravel(), e_ordering.ravel())\n</code></pre>"},{"location":"api/#visturing.ranking.calculate_pearson_stack","title":"<code>calculate_pearson_stack(s1, s2)</code>","text":"Source code in <code>visturing/ranking.py</code> <pre><code>def calculate_pearson_stack(s1, s2):\n    return stats.pearsonr(s1.ravel(), s2.ravel())\n</code></pre>"},{"location":"api/#visturing.ranking.calculate_spearman","title":"<code>calculate_spearman(experimental_curve, ideal_ordering)</code>","text":"Source code in <code>visturing/ranking.py</code> <pre><code>def calculate_spearman(experimental_curve, ideal_ordering):\n    ordered_curves = (-experimental_curve).argsort(axis=0)\n    ideal_ordering = np.array(ideal_ordering)[:,None].repeat(ordered_curves.shape[1], axis=1)\n    return calculate_correlations(ordered_curves, ideal_ordering)\n</code></pre>"},{"location":"api/#visturing.ranking.compare_ranges","title":"<code>compare_ranges(x1, x2)</code>","text":"Source code in <code>visturing/ranking.py</code> <pre><code>def compare_ranges(x1, x2):\n    m, M = False, False\n    if x1.min() &lt;= x2.min():\n        m = True\n    if x1.max() &gt;= x2.max():\n        M = True\n    return all((m, M))\n</code></pre>"},{"location":"api/#visturing.ranking.prepare_and_correlate","title":"<code>prepare_and_correlate(x_e, y_e, x_gt, y_gt)</code>","text":"Source code in <code>visturing/ranking.py</code> <pre><code>def prepare_and_correlate(x_e, y_e, x_gt, y_gt):\n    x_e, y_e, x_gt, y_gt = prepare_data(x_e, y_e, x_gt, y_gt)\n    return calculate_correlations(y_e, y_gt)\n</code></pre>"},{"location":"api/#visturing.ranking.prepare_and_correlate_order","title":"<code>prepare_and_correlate_order(x_e, y_e, x_gt, y_gt)</code>","text":"Source code in <code>visturing/ranking.py</code> <pre><code>def prepare_and_correlate_order(x_e, y_e, x_gt, y_gt):\n    x_e, y_e, x_gt, y_gt = prepare_data(x_e, y_e, x_gt, y_gt)\n    return calculate_correlations_with_ground_truth(y_e, y_gt)\n</code></pre>"},{"location":"api/#visturing.ranking.prepare_data","title":"<code>prepare_data(x_e, y_e, x_gt, y_gt)</code>","text":"<p>Prepares the data to be compared via correlations.</p> Source code in <code>visturing/ranking.py</code> <pre><code>def prepare_data(x_e, y_e, x_gt, y_gt):\n    \"\"\"Prepares the data to be compared via correlations.\"\"\"\n    if gt_shorter:=compare_ranges(x_e, x_gt):\n        x_wider = x_e\n        y_wider = y_e\n        x_shorter = x_gt\n        y_shorter = y_gt\n    else:\n        x_wider = x_gt\n        y_wider = y_gt\n        x_shorter = x_e\n        y_shorter = y_e\n\n    # print(x_wider.shape, y_wider.shape, x_shorter.shape, y_shorter.shape)\n    # if len(y_wider) &gt; 1:\n    #     y_wider_interp = np.array([np.interp(x_shorter, x_wider, row) for row in y_wider])\n    # else:\n    #     y_wider_interp = np.interp(x_shorter, x_wider, y_wider)\n    y_wider_interp = np.interp(x_shorter, x_wider, y_wider)\n    if gt_shorter:\n        return x_shorter, y_wider_interp, x_shorter, y_shorter\n    else:\n        return x_shorter, y_shorter, x_shorter, y_wider_interp\n</code></pre>"},{"location":"Examples/Differentiability/prop1_simpleNet/","title":"Prop 1","text":"In\u00a0[1]: Copied! <pre>import matplotlib.pyplot as plt\nfrom tqdm.auto import tqdm\n\nimport jax\nfrom jax import random, numpy as jnp\nimport flax.linen as nn\n</pre> import matplotlib.pyplot as plt from tqdm.auto import tqdm  import jax from jax import random, numpy as jnp import flax.linen as nn In\u00a0[2]: Copied! <pre>from visturing.properties.jax import prop1\n</pre> from visturing.properties.jax import prop1 In\u00a0[3]: Copied! <pre>data_path = \"../Data/Experiment_1\"\ngt_path = \"../Data/ground_truth\"\n</pre> data_path = \"../Data/Experiment_1\" gt_path = \"../Data/ground_truth\" In\u00a0[4]: Copied! <pre>class Model(nn.Module):\n    @nn.compact\n    def __call__(self, inputs):\n        b, h, w, c = inputs.shape\n        return nn.Conv(features=c, kernel_size=1, use_bias=False)(inputs)\n</pre> class Model(nn.Module):     @nn.compact     def __call__(self, inputs):         b, h, w, c = inputs.shape         return nn.Conv(features=c, kernel_size=1, use_bias=False)(inputs) In\u00a0[5]: Copied! <pre>model = Model()\nvariables = model.init(random.PRNGKey(42), jnp.ones((1,256,256,3)))\nparams = variables[\"params\"]\nparams\n</pre> model = Model() variables = model.init(random.PRNGKey(42), jnp.ones((1,256,256,3))) params = variables[\"params\"] params Out[5]: <pre>{'Conv_0': {'kernel': Array([[[ 0.26978174, -0.314012  ,  0.89799595],\n          [ 0.00569335,  0.13840543, -0.9635549 ],\n          [-0.33585423,  0.8945437 , -0.97497624]]], dtype=float32)}}</pre> In\u00a0[6]: Copied! <pre>def calculate_diffs(img1, img2):\n    output_a = model.apply({\"params\": params}, img1)\n    output_b = model.apply({\"params\": params}, img2)\n    return ((output_a - output_b)**2).mean(axis=(1,2,3))**(1/2)\n</pre> def calculate_diffs(img1, img2):     output_a = model.apply({\"params\": params}, img1)     output_b = model.apply({\"params\": params}, img2)     return ((output_a - output_b)**2).mean(axis=(1,2,3))**(1/2) In\u00a0[7]: Copied! <pre>results = prop1.evaluate(calculate_diffs,\n            data_path=data_path,\n            gt_path=gt_path)\n</pre> results = prop1.evaluate(calculate_diffs,             data_path=data_path,             gt_path=gt_path) In\u00a0[8]: Copied! <pre>plt.plot(results[\"lambdas\"], results[\"diffs\"])\nplt.show()\n</pre> plt.plot(results[\"lambdas\"], results[\"diffs\"]) plt.show() In\u00a0[9]: Copied! <pre>@jax.jit\ndef step(params, lr=0.01):\n    def loss_fn(params):\n        def calculate_diffs(img1, img2):\n            output_a = model.apply({\"params\": params}, img1)\n            output_b = model.apply({\"params\": params}, img2)\n            return ((output_a - output_b)**2).mean(axis=(1,2,3))**(1/2)\n\n        results = prop1.evaluate(calculate_diffs,\n                    data_path=data_path,\n                    gt_path=gt_path)\n        return -results[\"correlations\"][\"pearson\"]\n    loss, grad = jax.value_and_grad(loss_fn)(params)\n    params = jax.tree_util.tree_map(lambda x, g: x-g*lr, params, grad)\n    return params, loss, grad\n</pre> @jax.jit def step(params, lr=0.01):     def loss_fn(params):         def calculate_diffs(img1, img2):             output_a = model.apply({\"params\": params}, img1)             output_b = model.apply({\"params\": params}, img2)             return ((output_a - output_b)**2).mean(axis=(1,2,3))**(1/2)          results = prop1.evaluate(calculate_diffs,                     data_path=data_path,                     gt_path=gt_path)         return -results[\"correlations\"][\"pearson\"]     loss, grad = jax.value_and_grad(loss_fn)(params)     params = jax.tree_util.tree_map(lambda x, g: x-g*lr, params, grad)     return params, loss, grad In\u00a0[10]: Copied! <pre>EPOCHS = 1000\nlr = 0.01\nlosses, grads = [], []\nfor epoch in tqdm(range(EPOCHS)):\n    params, loss, grad = step(params)\n    losses.append(loss)\n    grads.append(grad)\n</pre> EPOCHS = 1000 lr = 0.01 losses, grads = [], [] for epoch in tqdm(range(EPOCHS)):     params, loss, grad = step(params)     losses.append(loss)     grads.append(grad) <pre>  0%|          | 0/1000 [00:00&lt;?, ?it/s]</pre> In\u00a0[11]: Copied! <pre>plt.plot(losses)\nplt.show()\n</pre> plt.plot(losses) plt.show() In\u00a0[12]: Copied! <pre>def calculate_diffs(img1, img2):\n    output_a = model.apply({\"params\": params}, img1)\n    output_b = model.apply({\"params\": params}, img2)\n    return ((output_a - output_b)**2).mean(axis=(1,2,3))**(1/2)\n</pre> def calculate_diffs(img1, img2):     output_a = model.apply({\"params\": params}, img1)     output_b = model.apply({\"params\": params}, img2)     return ((output_a - output_b)**2).mean(axis=(1,2,3))**(1/2) In\u00a0[13]: Copied! <pre>results = prop1.evaluate(calculate_diffs,\n            data_path=data_path,\n            gt_path=gt_path)\n</pre> results = prop1.evaluate(calculate_diffs,             data_path=data_path,             gt_path=gt_path) In\u00a0[14]: Copied! <pre>plt.plot(results[\"lambdas\"], results[\"diffs\"])\nplt.show()\n</pre> plt.plot(results[\"lambdas\"], results[\"diffs\"]) plt.show()"},{"location":"Examples/Differentiability/prop34_simpleNet_/","title":"Prop 3 & 4","text":"In\u00a0[1]: Copied! <pre>%load_ext autoreload\n%autoreload 2\n</pre> %load_ext autoreload %autoreload 2 In\u00a0[2]: Copied! <pre>import matplotlib.pyplot as plt\nfrom tqdm.auto import tqdm\n\nimport jax\nfrom jax import random, numpy as jnp\nimport flax.linen as nn\n</pre> import matplotlib.pyplot as plt from tqdm.auto import tqdm  import jax from jax import random, numpy as jnp import flax.linen as nn In\u00a0[3]: Copied! <pre>from visturing.properties.jax import prop3_4\n</pre> from visturing.properties.jax import prop3_4 In\u00a0[4]: Copied! <pre>data_path = \"../Data/Experiment_3_4\"\ngt_path = \"../Data/ground_truth\"\nfreqs = prop3_4.load_data(data_path)\n</pre> data_path = \"../Data/Experiment_3_4\" gt_path = \"../Data/ground_truth\" freqs = prop3_4.load_data(data_path) In\u00a0[5]: Copied! <pre>class Model(nn.Module):\n    @nn.compact\n    def __call__(self, inputs):\n        b, h, w, c = inputs.shape\n        return nn.Conv(features=c, kernel_size=5, use_bias=False)(inputs)\n</pre> class Model(nn.Module):     @nn.compact     def __call__(self, inputs):         b, h, w, c = inputs.shape         return nn.Conv(features=c, kernel_size=5, use_bias=False)(inputs) In\u00a0[6]: Copied! <pre>model = Model()\nvariables = model.init(random.PRNGKey(42), jnp.ones((1,256,256,3)))\nparams = variables[\"params\"]\nparams\n</pre> model = Model() variables = model.init(random.PRNGKey(42), jnp.ones((1,256,256,3))) params = variables[\"params\"] params Out[6]: <pre>{'Conv_0': {'kernel': Array([[[ 0.25343975,  0.37796202,  0.07228442],\n          [ 0.2832777 ,  0.02843482, -0.3120535 ],\n          [-0.05727616,  0.21281467, -0.21811679]],\n  \n         [[ 0.48485518,  0.0206414 , -0.15234476],\n          [-0.4451559 ,  0.257366  ,  0.15174802],\n          [ 0.22555478,  0.08806025, -0.09887113]],\n  \n         [[ 0.37739292, -0.43393105, -0.24370822],\n          [ 0.14681341, -0.26786864, -0.14960037],\n          [-0.09368402,  0.15809025,  0.47890887]],\n  \n         [[-0.32488084, -0.42462158,  0.14909363],\n          [-0.00518601,  0.00165081, -0.01637981],\n          [ 0.4389706 ,  0.3052182 , -0.19210207]],\n  \n         [[-0.30877265,  0.05764987, -0.03111272],\n          [ 0.28582865, -0.33615807, -0.11248872],\n          [-0.3428852 ,  0.29388985,  0.3956964 ]]], dtype=float32)}}</pre> In\u00a0[7]: Copied! <pre>def calculate_diffs(img1, img2):\n    output_a = model.apply({\"params\": params}, img1)\n    output_b = model.apply({\"params\": params}, img2)\n    return ((output_a - output_b)**2).mean(axis=(1,2,3))**(1/2)\n</pre> def calculate_diffs(img1, img2):     output_a = model.apply({\"params\": params}, img1)     output_b = model.apply({\"params\": params}, img2)     return ((output_a - output_b)**2).mean(axis=(1,2,3))**(1/2) In\u00a0[8]: Copied! <pre>results = prop3_4.evaluate(calculate_diffs,\n            data_path=data_path,\n            gt_path=gt_path)\n</pre> results = prop3_4.evaluate(calculate_diffs,             data_path=data_path,             gt_path=gt_path) In\u00a0[9]: Copied! <pre>results.keys()\n</pre> results.keys() Out[9]: <pre>dict_keys(['diffs_s', 'correlations'])</pre> In\u00a0[10]: Copied! <pre>fig, axes = plt.subplots()\nfor d, c in zip(results[\"diffs_s\"], [\"k\", \"r\", \"b\"]):\n    axes.plot(freqs, d, color=c)\nplt.show()\n</pre> fig, axes = plt.subplots() for d, c in zip(results[\"diffs_s\"], [\"k\", \"r\", \"b\"]):     axes.plot(freqs, d, color=c) plt.show() In\u00a0[23]: Copied! <pre>@jax.jit\ndef step(params, lr=0.01):\n    def loss_fn(params):\n        def calculate_diffs(img1, img2):\n            output_a = model.apply({\"params\": params}, img1)\n            output_b = model.apply({\"params\": params}, img2)\n            return ((output_a - output_b)**2).mean(axis=(1,2,3))#**(1/2)\n\n        results = prop3_4.evaluate(calculate_diffs,\n                    data_path=data_path,\n                    gt_path=gt_path)\n        return -results[\"correlations\"][\"pearson\"]\n    loss, grad = jax.value_and_grad(loss_fn)(params)\n    params = jax.tree_util.tree_map(lambda x, g: x-g*lr, params, grad)\n    return params, loss, grad\n</pre> @jax.jit def step(params, lr=0.01):     def loss_fn(params):         def calculate_diffs(img1, img2):             output_a = model.apply({\"params\": params}, img1)             output_b = model.apply({\"params\": params}, img2)             return ((output_a - output_b)**2).mean(axis=(1,2,3))#**(1/2)          results = prop3_4.evaluate(calculate_diffs,                     data_path=data_path,                     gt_path=gt_path)         return -results[\"correlations\"][\"pearson\"]     loss, grad = jax.value_and_grad(loss_fn)(params)     params = jax.tree_util.tree_map(lambda x, g: x-g*lr, params, grad)     return params, loss, grad In\u00a0[24]: Copied! <pre>EPOCHS = 100\nlr = 0.01\nlosses, grads = [], []\n# with jax.debug_nans(True):\nfor epoch in tqdm(range(EPOCHS)):\n    params, loss, grad = step(params, lr)\n    # loss, grad = jax.value_and_grad(loss_fn)(params)\n    # params = jax.tree_util.tree_map(lambda x, g: x-g*lr, params, grad)\n    losses.append(loss)\n    grads.append(grad)\n</pre> EPOCHS = 100 lr = 0.01 losses, grads = [], [] # with jax.debug_nans(True): for epoch in tqdm(range(EPOCHS)):     params, loss, grad = step(params, lr)     # loss, grad = jax.value_and_grad(loss_fn)(params)     # params = jax.tree_util.tree_map(lambda x, g: x-g*lr, params, grad)     losses.append(loss)     grads.append(grad) <pre>  0%|          | 0/100 [00:00&lt;?, ?it/s]</pre> In\u00a0[25]: Copied! <pre>plt.plot(losses)\nplt.show()\n</pre> plt.plot(losses) plt.show() In\u00a0[26]: Copied! <pre>def calculate_diffs(img1, img2):\n    output_a = model.apply({\"params\": params}, img1)\n    output_b = model.apply({\"params\": params}, img2)\n    return ((output_a - output_b)**2).mean(axis=(1,2,3))**(1/2)\n</pre> def calculate_diffs(img1, img2):     output_a = model.apply({\"params\": params}, img1)     output_b = model.apply({\"params\": params}, img2)     return ((output_a - output_b)**2).mean(axis=(1,2,3))**(1/2) In\u00a0[27]: Copied! <pre>results = prop3_4.evaluate(calculate_diffs,\n            data_path=data_path,\n            gt_path=gt_path)\n</pre> results = prop3_4.evaluate(calculate_diffs,             data_path=data_path,             gt_path=gt_path) In\u00a0[28]: Copied! <pre>fig, axes = plt.subplots()\nfor d, c in zip(results[\"diffs_s\"], [\"k\", \"r\", \"b\"]):\n    axes.plot(freqs, d, color=c)\n\nplt.show()\n</pre> fig, axes = plt.subplots() for d, c in zip(results[\"diffs_s\"], [\"k\", \"r\", \"b\"]):     axes.plot(freqs, d, color=c)  plt.show()"}]}